# ================== Ø¨Ø®Ø´ Û±: ØªÙ†Ø¸ÛŒÙ…Ø§ØªØŒ Ø§ÛŒÙ…Ù¾ÙˆØ±Øªâ€ŒÙ‡Ø§ØŒ ØªÙ„Ú¯Ø±Ø§Ù…ØŒ Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ Ù¾Ø§ÛŒÙ‡ ==================
import os
import time
import random
import requests
import pandas as pd
import ta
import glob
import json
import warnings
import csv

from datetime import datetime, timezone, timedelta
from dataclasses import dataclass, field
from typing import Dict, Optional, List, Tuple

warnings.filterwarnings("ignore", message="The NumPy module was reloaded")

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØªÙ„Ú¯Ø±Ø§Ù…
TOKEN = "8247452747:AAFCwJukYuFd3cRctYk1Q3yFW_r_LJl4Elk"                 # ØªÙˆÚ©Ù† ØªÙ„Ú¯Ø±Ø§Ù…
CHAT_ID_USER = "8384524553"          # Ø¢ÛŒâ€ŒØ¯ÛŒ Ú†Øª Ø®ØµÙˆØµÛŒ (Ø¯Ø§ÛŒØ±Ú©Øª Ø®ÙˆØ¯Øª)
CHAT_ID_CHANNEL = "-1002024805980"       # Ø¢ÛŒâ€ŒØ¯ÛŒ Ú©Ø§Ù†Ø§Ù„ Ø®ØµÙˆØµÛŒ (Ø¨Ø±Ø§ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§)
BOT_API = f"https://api.telegram.org/bot{TOKEN}"

# Ø§ÙØ²ÙˆÙ†Ù‡ Ú©Ù†ØªØ±Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø®ÙˆØ¯Ú©Ø§Ø±
ENABLE_AUTO_REPORTS = False  # Ø§Ú¯Ø± True Ø´ÙˆØ¯ØŒ Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ù†ØªÙ‡Ø§ÛŒ run_once ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´ÙˆØ¯

# ================== Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù…Ø³ÛŒØ±Ù‡Ø§ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÙ‡ ==================
LOG_DIR = "logs"
LOG_BASE_NAME = "signals"
LOG_EXT = ".csv"

def ensure_log_dir():
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

def get_current_log_path():
    ensure_log_dir()
    return os.path.join(LOG_DIR, f"{LOG_BASE_NAME}{LOG_EXT}")

def init_log(path):
    ensure_log_dir()
    if not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            f.write("timestamp,symbol,signal,entry,stop,target1,target2,target3,rrr,tf,analysis,data_source,reason,result\n")

# Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
REPORTS_DIR = "logs"
REPORTS_BASE_NAME = "reports"
REPORTS_EXT = ".csv"

def ensure_reports_dir():
    if not os.path.exists(REPORTS_DIR):
        os.makedirs(REPORTS_DIR)

def get_reports_path():
    ensure_reports_dir()
    return os.path.join(REPORTS_DIR, f"{REPORTS_BASE_NAME}{REPORTS_EXT}")

def init_reports_log(path):
    ensure_reports_dir()
    if not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            f.write("timestamp,type,message\n")

# Ø§Ø¬Ø±Ø§ÛŒ Ø§ÙˆÙ„ÛŒÙ‡
init_log(get_current_log_path())
init_reports_log(get_reports_path())

# ÙÙ‡Ø±Ø³Øª Ú©ÙˆÛŒÙ†â€ŒÙ‡Ø§
SYMBOLS = [
    "bitcoin","ethereum","binancecoin","solana","ripple","dogecoin","cardano",
    "avalanche-2","polkadot","chainlink","litecoin","bitcoin-cash","tron",
    "cosmos","aave","uniswap","near","internet-computer","ethereum-classic",
    "the-open-network","sui","aptos","ondo-finance","arbitrum","optimism","shiba-inu",
    "pepe","band-protocol","stellar","filecoin","the-sandbox","worldcoin","mantra",
    "pancakeswap-token","algorand","pax-gold"
]

# Ù†Ù…Ø§Ø¯Ù‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ÛŒ
symbol_display = {
    "bitcoin": "BTC","ethereum": "ETH","binancecoin": "BNB","solana": "SOL",
    "ripple": "XRP","dogecoin": "DOGE","cardano": "ADA","avalanche-2": "AVAX",
    "polkadot": "DOT","chainlink": "LINK","litecoin": "LTC","bitcoin-cash": "BCH",
    "tron": "TRX","cosmos": "ATOM","aave": "AAVE","uniswap": "UNI",
    "near": "NEAR","internet-computer": "ICP","ethereum-classic": "ETC",
    "the-open-network": "TON","sui": "SUI","aptos": "APT","ondo-finance": "ONDO",
    "arbitrum": "ARB","optimism": "OP","shiba-inu": "SHIB","pepe": "PEPE",
    "band-protocol": "BAND","stellar": "XLM","filecoin": "FIL","the-sandbox": "SAND",
    "worldcoin": "WLD","mantra": "OM","pancakeswap-token": "CAKE","algorand": "ALGO",
    "pax-gold": "PAXG"
}

# ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…â€ŒÙ‡Ø§
TIMEFRAMES = ["30min","1h","2h","4h"]

# Ù…Ø³ÛŒØ± Ù„Ø§Ú¯ ÙˆØ§Ø­Ø¯ Ùˆ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
def get_current_log_path():
    return os.path.join("logs", "signals.csv")

# Ù¾Ø§ÛŒØ¯Ø§Ø±Ø³Ø§Ø²ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§
LAST_SIGNALS_PATH = "last_signals.json"
last_signals: Dict[Tuple[str, str], Dict[str, str]] = {}

def load_last_signals():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø§Ø² ÙØ§ÛŒÙ„ JSON (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯)"""
    global last_signals
    try:
        if os.path.exists(LAST_SIGNALS_PATH):
            with open(LAST_SIGNALS_PATH, "r", encoding="utf-8") as f:
                last_signals = json.load(f)
        else:
            last_signals = {}
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± load_last_signals:", e)
        last_signals = {}

# Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ø§Ù†Ú¯ÛŒØ²Ø´ÛŒ
motivation_messages = [
    "â³ ØµØ¨Ø± ÛŒØ¹Ù†ÛŒ ÙˆØ§Ú©Ù†Ø´ Ø¯Ø± Ø¨Ù‡ØªØ±ÛŒÙ† ÙØ±ØµØªØŒ Ù†Ù‡ Ø¯Ø± Ø§ÙˆÙ„ÛŒÙ† ÙØ±ØµØª ğŸ’¡",
    "ğŸ’ª ØªØ±ÛŒØ¯Ø± Ù…ÙˆÙÙ‚ Ú©Ø³ÛŒÙ‡ Ú©Ù‡ Ù…Ù†ØªØ¸Ø± Ø¨Ù‡ØªØ±ÛŒÙ† Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…ÛŒâ€ŒÙ…ÙˆÙ†Ù‡.",
    "ğŸ§˜â€â™‚ï¸ Ø¢Ø±Ø§Ù…Ø´ = ØªØµÙ…ÛŒÙ… Ø¯Ø±Ø³Øª. Ø¨Ø§Ø²Ø§Ø± Ù‡Ù…ÛŒØ´Ù‡ ÙØ±ØµØª Ù…ÛŒâ€ŒØ¯Ù‡.",
    "ğŸš€ Ù…ÙˆÙÙ‚ÛŒØª Ø¯Ø± ØªØ±ÛŒØ¯ = ØµØ¨Ø± âœš Ù†Ø¸Ù… âœš Ù…Ø¯ÛŒØ±ÛŒØª Ø³Ø±Ù…Ø§ÛŒÙ‡"
]

# Ø³ÙˆÛŒÛŒÚ† ØªØ§ÛŒÙ…â€ŒØ²ÙˆÙ†
USE_IRAN_TZ = True
IRAN_TZ = timezone(timedelta(hours=3, minutes=30))

def now_dt():
    return datetime.now(IRAN_TZ if USE_IRAN_TZ else timezone.utc)

# ================== ØªÙˆØ§Ø¨Ø¹ Ø§Ø±Ø³Ø§Ù„ ==================

# Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ â†’ Ù‡Ù… Ú©Ø§Ù†Ø§Ù„ + Ù‡Ù… Ú†Øª Ø®ØµÙˆØµÛŒ
def send_signal(text: str):
    try:
        if not TOKEN:
            return
        url = f"{BOT_API}/sendMessage"
        if CHAT_ID_CHANNEL:
            requests.post(url, data={"chat_id": CHAT_ID_CHANNEL, "text": text}, timeout=12)
        if CHAT_ID_USER:
            requests.post(url, data={"chat_id": CHAT_ID_USER, "text": text}, timeout=12)
        return
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„:", e)
        return

# Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ùˆ Ù…Ù†Ùˆ â†’ ÙÙ‚Ø· Ú†Øª Ø®ØµÙˆØµÛŒ
def send_report(text: str):
    try:
        if not TOKEN or not CHAT_ID_USER:
            return
        url = f"{BOT_API}/sendMessage"
        requests.post(url, data={"chat_id": CHAT_ID_USER, "text": text}, timeout=12)
        return
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´:", e)
        return

    # ================== Ø¨Ø®Ø´ Û±/Û²: Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ ==================
import pandas as pd
from datetime import datetime, timedelta, timezone

# ---------- Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ----------
def _read_logs_df():
    try:
        df = pd.read_csv(get_current_log_path(), encoding="utf-8")
        if "timestamp" in df.columns:
            df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, errors="coerce")
        return df
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯:", e)
        return pd.DataFrame()

# ---------- outcome Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± ----------
def outcome(row):
    r = str(row.get("result", "")).strip().lower()
    reason_raw = str(row.get("reason", "")).strip()
    reason = reason_raw.lower()

    stop_keys = ["stopped", "stop", "Ø§Ø³ØªØ§Ù¾", "Ø¨Ø§Ø·Ù„", "Ù„ØºÙˆ"]
    hit_keys = ["hit_target", "target1", "target", "ØªØ§Ø±Ú¯Øª", "ØªØ§Ø±Ú¯Øª Ø§ÙˆÙ„"]

    if r in ["stopped", "stop"] or any(k in reason for k in stop_keys):
        return "stopped"
    if r in ["hit_target"] or any(k in reason for k in hit_keys):
        return "hit_target"
    return "active"

# ---------- Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø®Ù„Ø§ØµÙ‡ ----------
def _aggregate_performance(df):
    total = len(df)
    stopped = sum(outcome(r) == "stopped" for _, r in df.iterrows())
    hit = sum(outcome(r) == "hit_target" for _, r in df.iterrows())
    active = total - stopped - hit
    return {"total": total, "stopped": stopped, "hit": hit, "active": active}

def _build_summary_message(title, stats):
    return (f"{title}\n"
            f"- Ú©Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: {stats['total']}\n"
            f"- ØªØ§Ø±Ú¯Øª Ø®ÙˆØ±Ø¯Ù‡: {stats['hit']}\n"
            f"- Ø§Ø³ØªØ§Ù¾ Ø®ÙˆØ±Ø¯Ù‡: {stats['stopped']}\n"
            f"- ÙØ¹Ø§Ù„: {stats['active']}")

# ---------- Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ ----------
def send_daily_summary(return_only: bool = True):
    df = _read_logs_df()
    if df.empty:
        msg = "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡:\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    else:
        cutoff = pd.Timestamp.now(tz=IRAN_TZ if USE_IRAN_TZ else timezone.utc) - pd.Timedelta(days=1)
        df_d = df[df["timestamp"] >= cutoff]
        stats = _aggregate_performance(df_d)
        msg = _build_summary_message("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡", stats)

    if return_only:
        return msg
    else:
        send_report(msg)
        return msg

        # ================== Ø¨Ø®Ø´ Û±/Û³: Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù‡ÙØªÚ¯ÛŒØŒ Ù…Ø§Ù‡Ø§Ù†Ù‡ ==================
import pandas as pd
from datetime import datetime, timedelta, timezone

# ---------- Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ----------
def _read_logs_df():
    try:
        df = pd.read_csv(get_current_log_path(), encoding="utf-8")
        if "timestamp" in df.columns:
            df["timestamp"] = pd.to_datetime(df["timestamp"], utc=True, errors="coerce")
        return df
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ù„Ø§Ú¯:", e)
        return pd.DataFrame()

# ---------- outcome Ø¯Ù‚ÛŒÙ‚â€ŒØªØ± ----------
def outcome(row):
    r = str(row.get("result", "")).strip().lower()
    reason_raw = str(row.get("reason", "")).strip()
    reason = reason_raw.lower()

    stop_keys = ["stopped", "stop", "Ø§Ø³ØªØ§Ù¾", "Ø¨Ø§Ø·Ù„", "Ù„ØºÙˆ"]
    hit_keys = ["hit_target", "target1", "target", "ØªØ§Ø±Ú¯Øª", "ØªØ§Ø±Ú¯Øª Ø§ÙˆÙ„"]

    if r in ["stopped", "stop"] or any(k in reason for k in stop_keys):
        return "stopped"
    if r in ["hit_target"] or any(k in reason for k in hit_keys):
        return "hit_target"
    return "active"

# ---------- Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ø®Ù„Ø§ØµÙ‡ ----------
def _aggregate_performance(df):
    total = len(df)
    stopped = sum(outcome(r) == "stopped" for _, r in df.iterrows())
    hit = sum(outcome(r) == "hit_target" for _, r in df.iterrows())
    active = total - stopped - hit
    return {"total": total, "stopped": stopped, "hit": hit, "active": active}

def _build_summary_message(title, stats):
    return (f"{title}\n"
            f"- Ú©Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: {stats['total']}\n"
            f"- ØªØ§Ø±Ú¯Øª Ø®ÙˆØ±Ø¯Ù‡: {stats['hit']}\n"
            f"- Ø§Ø³ØªØ§Ù¾ Ø®ÙˆØ±Ø¯Ù‡: {stats['stopped']}\n"
            f"- ÙØ¹Ø§Ù„: {stats['active']}")

# ---------- Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ ----------
def send_daily_summary(return_only: bool = True):
    df = _read_logs_df()
    if df.empty:
        msg = "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡:\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    else:
        cutoff = pd.Timestamp.now(tz=IRAN_TZ if USE_IRAN_TZ else timezone.utc) - pd.Timedelta(days=1)
        df_d = df[df["timestamp"] >= cutoff]
        stats = _aggregate_performance(df_d)
        msg = _build_summary_message("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡", stats)

    if return_only:
        return msg
    else:
        send_report(msg)
        return msg

# ---------- Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ ----------
def send_weekly_summary(return_only: bool = True):
    df = _read_logs_df()
    if df.empty:
        msg = "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ:\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    else:
        now = pd.Timestamp.now(tz=IRAN_TZ if USE_IRAN_TZ else timezone.utc)
        start = now - pd.Timedelta(days=7)
        df_w = df[df["timestamp"] >= start]
        stats = _aggregate_performance(df_w)
        msg = _build_summary_message("ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ", stats)

    if return_only:
        return msg
    else:
        send_report(msg)
        return msg

# ---------- Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ----------
def send_monthly_summary(return_only: bool = True):
    df = _read_logs_df()
    if df.empty:
        msg = "ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡:\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    else:
        now = pd.Timestamp.now(tz=IRAN_TZ if USE_IRAN_TZ else timezone.utc)
        start = now - pd.Timedelta(days=30)
        df_m = df[df["timestamp"] >= start]
        stats = _aggregate_performance(df_m)
        msg = _build_summary_message("ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡", stats)

    if return_only:
        return msg
    else:
        send_report(msg)
        return msg

# ================== Ø¨Ø®Ø´ Û²: Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ùˆ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ ==================
def fetch_data(coin_id, days=30):
    try:
        # Ø§Ø³ØªØ«Ù†Ø§ Ø¨Ø±Ø§ÛŒ MATIC (Ø§ÙˆÙ„ÙˆÛŒØª Ø¨Ø§ Binance)
        if coin_id == "polygon":
            try:
                symbol = "MATICUSDT"
                url = "https://api.binance.com/api/v3/klines"
                r = requests.get(url, params={"symbol": symbol, "interval": "1h", "limit": 500}, timeout=20)
                data = r.json()
                if isinstance(data, list) and len(data) > 0:
                    df = pd.DataFrame(data, columns=[
                        "ts","Open","High","Low","Close","Volume","c1","c2","c3","c4","c5","c6"
                    ])
                    ts_col = pd.to_datetime(pd.to_numeric(df["ts"]), unit="ms", utc=True)
                    df["ts"] = ts_col.dt.tz_convert(IRAN_TZ) if USE_IRAN_TZ else ts_col
                    for col in ["Open","High","Low","Close","Volume"]:
                        df[col] = pd.to_numeric(df[col], errors="coerce")
                    df = df.dropna()
                    if not df.empty:
                        return df[["ts","Open","High","Low","Close","Volume"]].set_index("ts"), "Binance (MATIC priority)"
            except Exception as e:
                print(f"âš ï¸ MATIC â†’ Ø®Ø·Ø§ Binance: {e}")

        # Ú©ÙˆÛŒÙ†â€ŒÙ‡Ø§ÛŒ Ø¨Ø²Ø±Ú¯: CoinGecko OHLC
        big_coins = ["bitcoin","ethereum","binancecoin","solana","ripple","dogecoin","cardano"]
        if coin_id in big_coins:
            try:
                url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/ohlc"
                r = requests.get(url, params={"vs_currency": "usd", "days": days}, timeout=20)
                data = r.json()
                if isinstance(data, list) and len(data) > 0:
                    df = pd.DataFrame(data, columns=["ts","Open","High","Low","Close"])
                    ts_col = pd.to_datetime(pd.to_numeric(df["ts"]), unit="ms", utc=True)
                    df["ts"] = ts_col.dt.tz_convert(IRAN_TZ) if USE_IRAN_TZ else ts_col
                    for col in ["Open","High","Low","Close"]:
                        df[col] = pd.to_numeric(df[col], errors="coerce")
                    df = df.dropna()
                    if not df.empty:
                        return df.set_index("ts"), "CoinGecko OHLC"
            except Exception as e:
                print(f"âš ï¸ {coin_id.upper()} â†’ Ø®Ø·Ø§ OHLC: {e}")

        # CoinGecko MarketChart (Resample Ø¨Ù‡ 1h)
        try:
            url = f"https://api.coingecko.com/api/v3/coins/{coin_id}/market_chart"
            r = requests.get(url, params={"vs_currency": "usd", "days": days}, timeout=20)
            data = r.json()
            if "prices" in data and data["prices"]:
                dfp = pd.DataFrame(data["prices"], columns=["ts","price"])
                ts_col = pd.to_datetime(pd.to_numeric(dfp["ts"]), unit="ms", utc=True)
                dfp["ts"] = ts_col.dt.tz_convert(IRAN_TZ) if USE_IRAN_TZ else ts_col
                dfp = dfp.set_index("ts").sort_index()
                o = dfp["price"].resample("1h").first()
                h = dfp["price"].resample("1h").max()
                l = dfp["price"].resample("1h").min()
                c = dfp["price"].resample("1h").last()
                df = pd.DataFrame({"Open": o, "High": h, "Low": l, "Close": c}).dropna()
                if not df.empty:
                    return df, "CoinGecko MarketChart"
        except Exception as e:
            print(f"âš ï¸ {coin_id.upper()} â†’ Ø®Ø·Ø§ MarketChart: {e}")

        # Binance fallback
        try:
            sym = symbol_display.get(coin_id, "").upper()
            if sym:
                symbol = f"{sym}USDT"
                url = "https://api.binance.com/api/v3/klines"
                r = requests.get(url, params={"symbol": symbol, "interval": "1h", "limit": 500}, timeout=20)
                data = r.json()
                if isinstance(data, list) and len(data) > 0:
                    df = pd.DataFrame(data, columns=[
                        "ts","Open","High","Low","Close","Volume","c1","c2","c3","c4","c5","c6"
                    ])
                    ts_col = pd.to_datetime(pd.to_numeric(df["ts"]), unit="ms", utc=True)
                    df["ts"] = ts_col.dt.tz_convert(IRAN_TZ) if USE_IRAN_TZ else ts_col
                    for col in ["Open","High","Low","Close","Volume"]:
                        df[col] = pd.to_numeric(df[col], errors="coerce")
                    df = df.dropna()
                    if not df.empty:
                        return df[["ts","Open","High","Low","Close","Volume"]].set_index("ts"), "Binance"
        except Exception as e:
            print(f"âš ï¸ {coin_id.upper()} â†’ Ø®Ø·Ø§ Binance: {e}")

        # KuCoin fallback
        try:
            sym = symbol_display.get(coin_id, "").upper()
            if sym:
                symbol = f"{sym}-USDT"
                url = "https://api.kucoin.com/api/v1/market/candles"
                r = requests.get(url, params={"symbol": symbol, "type": "1hour"}, timeout=20)
                data = r.json()
                if data.get("data"):
                    df = pd.DataFrame(data["data"], columns=["ts","Open","Close","High","Low","Volume","Turnover"])
                    ts_col = pd.to_datetime(pd.to_numeric(df["ts"]), unit="s", utc=True)
                    df["ts"] = ts_col.dt.tz_convert(IRAN_TZ) if USE_IRAN_TZ else ts_col
                    for col in ["Open","High","Low","Close","Volume"]:
                        df[col] = pd.to_numeric(df[col], errors="coerce")
                    df = df.dropna()
                    if not df.empty:
                        return df[["ts","Open","Close","High","Low","Volume"]].set_index("ts"), "KuCoin"
        except Exception as e:
            print(f"âš ï¸ {coin_id.upper()} â†’ Ø®Ø·Ø§ KuCoin: {e}")

        # SimplePrice fallback
        try:
            url = "https://api.coingecko.com/api/v3/simple/price"
            r = requests.get(url, params={"ids": coin_id, "vs_currencies": "usd"}, timeout=10)
            data = r.json()
            if coin_id in data and "usd" in data[coin_id]:
                price = float(data[coin_id]["usd"])
                now_ts = pd.Timestamp.now(tz=IRAN_TZ) if USE_IRAN_TZ else pd.Timestamp.utcnow().tz_localize("UTC")
                df = pd.DataFrame(
                    {"Open": [price], "High": [price], "Low": [price], "Close": [price]},
                    index=[now_ts]
                )
                return df, "SimplePrice"
        except Exception as e:
            print(f"âš ï¸ {coin_id.upper()} â†’ Ø®Ø·Ø§ SimplePrice: {e}")

        print(f"âŒ {coin_id.upper()} â†’ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯")
        return None, None

    except Exception as e:
        print(f"â›” Ø®Ø·Ø§ Ú©Ù„ÛŒ fetch_data Ø¨Ø±Ø§ÛŒ {coin_id}: {e}")
        return None, None

        # ------------------ Ø¨Ø®Ø´ Û³: Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ ------------------
def get_indicator_signal(df):
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ:
    - EMA9 Ùˆ EMA21 Ø¨Ø±Ø§ÛŒ Ú©Ø±Ø§Ø³ Ú©ÙˆØªØ§Ù‡â€ŒÙ…Ø¯Øª
    - EMA50 Ø¨Ø±Ø§ÛŒ Ø±ÙˆÙ†Ø¯ Ú©Ù„ÛŒ
    - MACD (25,7,80) Ø¨Ø±Ø§ÛŒ Ù…ÙˆÙ…Ù†ØªÙˆÙ…
    - RSI Ø¨Ø±Ø§ÛŒ Ù‚Ø¯Ø±Øª Ù†Ø³Ø¨ÛŒ
    """
    if df is None or df.empty or len(df) < 60:
        return None

    close = df["Close"]

    # EMA Ù‡Ø§
    ema9  = ta.trend.EMAIndicator(close, 9).ema_indicator()
    ema21 = ta.trend.EMAIndicator(close, 21).ema_indicator()
    ema50 = ta.trend.EMAIndicator(close, 50).ema_indicator()

    # MACD Ø¨Ø§ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ÛŒ (25,7,80)
    macd  = ta.trend.MACD(close, window_slow=25, window_fast=7, window_sign=80)

    # RSI
    rsi   = ta.momentum.RSIIndicator(close, 14).rsi()

    # --- Ø´Ø±Ø· Ø®Ø±ÛŒØ¯ ---
    if ema9.iloc[-1] > ema21.iloc[-1] \
       and close.iloc[-1] > ema50.iloc[-1] \
       and macd.macd().iloc[-1] > macd.macd_signal().iloc[-1] \
       and rsi.iloc[-1] > 55:
        return "buy"

    # --- Ø´Ø±Ø· ÙØ±ÙˆØ´ ---
    if ema9.iloc[-1] < ema21.iloc[-1] \
       and close.iloc[-1] < ema50.iloc[-1] \
       and macd.macd().iloc[-1] < macd.macd_signal().iloc[-1] \
       and rsi.iloc[-1] < 45:
        return "sell"

    return None
# ================== Ø¨Ø®Ø´ Û´: Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ÛŒØŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ù„Ø§Ø³ÛŒÚ© Ùˆ Wyckoff ==================
def candle_patterns(df):
    """
    ØªØ´Ø®ÛŒØµ Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ÛŒ Ø³Ø§Ø¯Ù‡:
    - Bullish/Bearish Engulfing
    - Hammer / Hanging Man
    - Double Top / Double Bottom
    """
    if df is None or df.empty or len(df) < 12:
        return None

    o = df["Open"].iloc[-2:]
    h = df["High"].iloc[-2:]
    l = df["Low"].iloc[-2:]
    c = df["Close"].iloc[-2:]

    # Bullish Engulfing
    if c.iloc[-2] < o.iloc[-2] and c.iloc[-1] > o.iloc[-1] \
       and c.iloc[-1] > o.iloc[-2] and o.iloc[-1] < c.iloc[-2]:
        return "bullish_engulfing"

    # Bearish Engulfing
    if c.iloc[-2] > o.iloc[-2] and c.iloc[-1] < o.iloc[-1] \
       and c.iloc[-1] < o.iloc[-2] and o.iloc[-1] > c.iloc[-2]:
        return "bearish_engulfing"

    # Hammer / Hanging Man
    body  = abs(c.iloc[-1] - o.iloc[-1])
    lower = min(o.iloc[-1], c.iloc[-1]) - l.iloc[-1]
    upper = h.iloc[-1] - max(c.iloc[-1], o.iloc[-1])

    if body < lower * 0.3 and upper < body:
        return "hammer"
    if body < lower * 0.3 and upper > body:
        return "hanging_man"

    # Double Top / Double Bottom
    if abs(df["High"].tail(10).max() - df["High"].iloc[-1]) < 0.01 * df["High"].tail(10).mean():
        return "double_top"
    if abs(df["Low"].tail(10).min() - df["Low"].iloc[-1]) < 0.01 * df["Low"].tail(10).mean():
        return "double_bottom"

    return None

def get_classic_signal(df):
    """
    Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ù„Ø§Ø³ÛŒÚ© Ø¨Ø± Ø§Ø³Ø§Ø³:
    - Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ Ú©Ù†Ø¯Ù„ÛŒ
    - RSI
    - Ø´Ú©Ø³Øª Ø³Ù‚Ù/Ú©Ù Ø§Ø®ÛŒØ±
    """
    if df is None or df.empty or len(df) < 25:
        return None

    c = df["Close"].iloc[-1]
    rsi_val = ta.momentum.RSIIndicator(df["Close"], 14).rsi().iloc[-1]
    pattern = candle_patterns(df)

    if pattern in ["bullish_engulfing", "hammer", "double_bottom"] and rsi_val > 45:
        return "buy"
    if pattern in ["bearish_engulfing", "hanging_man", "double_top"] and rsi_val < 55:
        return "sell"

    if c > df["High"].iloc[-4:-1].max() and rsi_val > 50:
        return "buy"
    if c < df["Low"].iloc[-4:-1].min() and rsi_val < 50:
        return "sell"

    return None

def wyckoff_phase(df):
    """
    ØªØ´Ø®ÛŒØµ ÙØ§Ø²Ù‡Ø§ÛŒ ÙˆØ§ÛŒÚ©ÙˆÙ (Ø³Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡):
    - Accumulation
    - Distribution
    """
    if df is None or df.empty or len(df) < 30:
        return None

    closes = df["Close"].tail(20)
    highs  = df["High"].tail(20)
    lows   = df["Low"].tail(20)
    rng    = highs.max() - lows.min()

    if rng / closes.mean() < 0.1:
        # Ù†Ø±Ù…â€ŒØªØ± Ø§Ø² Ø´Ø±Ø· ÛŒÚ©Ù†ÙˆØ§Ø®Øª Ø¨Ø§Ù„Ø§/Ù¾Ø§ÛŒÛŒÙ†
        ma = closes.rolling(5).mean().iloc[-1]
        prev_ma = closes.rolling(5).mean().iloc[-5]
        if closes.iloc[-1] > ma and ma > prev_ma:
            return "accumulation"
        if closes.iloc[-1] < ma and ma < prev_ma:
            return "distribution"

    return None

# ================== Ø¨Ø®Ø´ Ûµ: SL/TPØŒ Ù‡Ù…â€ŒØ¬Ù‡ØªÛŒØŒ ÙØ±Ù…Øª Ù¾ÛŒØ§Ù… Ùˆ Ø³Ø§Ø®Øª Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ ==================
def calculate_sl_tp(entry, direction, df):
    """
    Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø­Ø¯ Ø¶Ø±Ø± Ùˆ ØªØ§Ø±Ú¯Øªâ€ŒÙ‡Ø§ Ø¨Ø± Ø§Ø³Ø§Ø³ ATR.
    Ø´Ø±Ø·: RRR Ø¨Ø§ÛŒØ¯ >= 2.5 Ø¨Ø§Ø´Ø¯.
    """
    if df is None or df.empty or len(df) < 20:
        return None, None, None

    atr = ta.volatility.AverageTrueRange(
        df["High"], df["Low"], df["Close"], 14
    ).average_true_range().iloc[-1]

    if pd.isna(atr) or atr <= 0:
        return None, None, None

    stop = entry - 1.5 * atr if direction == "buy" else entry + 1.5 * atr
    targets = [
        entry + k * atr if direction == "buy" else entry - k * atr
        for k in (5, 10, 15)
    ]

    risk = abs(entry - stop)
    reward = abs(targets[0] - entry)
    rrr = reward / risk if risk > 0 else 0.0

    if rrr < 2.5:
        return None, None, None

    return stop, targets, rrr

def is_aligned(coin_id: str, tf: str, signal: str, df_base: pd.DataFrame) -> bool:
    """
    Ø¨Ø±Ø±Ø³ÛŒ Ù‡Ù…â€ŒØ¬Ù‡ØªÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø§ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø§Ù„Ø§ØªØ±.
    Ø§Ú¯Ø± Ø¯Ø§Ø¯Ù‡ Ú©Ø§ÙÛŒ Ù†Ø¨Ø§Ø´Ø¯ ÛŒØ§ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø§Ù„Ø§ØªØ± ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ø¯ØŒ True Ø¨Ø±Ù…ÛŒâ€ŒÚ¯Ø±Ø¯Ø§Ù†Ø¯.
    """
    tf_order = {"30min": "1h", "1h": "2h", "2h": "4h", "4h": None}
    higher_tf = tf_order.get(tf)

    if higher_tf is None:
        return True

    df_higher = build_candles(df_base, higher_tf)
    if df_higher is None or df_higher.empty:
        return True

    sig_higher = get_indicator_signal(df_higher) or get_classic_signal(df_higher)
    return sig_higher == signal

def format_price(value: float) -> str:
    if value >= 1000:
        return f"{value:.2f}"
    elif value >= 1:
        return f"{value:.4f}"
    else:
        return f"{value:.8f}"

def format_signal(symbol_id, sig, entry, targets, stop, tf, analysis_type, rrr, reason=None):
    display = symbol_display.get(symbol_id, symbol_id.upper())
    targets = sorted(targets) if sig == "buy" else sorted(targets, reverse=True)

    txt  = f"ğŸ“Š Ø³ÛŒÚ¯Ù†Ø§Ù„ {display}\n\n"
    txt += f"âœ… {sig.upper()} | ÙˆØ±ÙˆØ¯: {format_price(entry)}\n"
    txt += "ğŸ¯ ØªØ§Ø±Ú¯Øªâ€ŒÙ‡Ø§:\n"
    for i, t in enumerate(targets, 1):
        txt += f"{i}) {format_price(t)}\n"

    txt += f"ğŸ›‘ Ø­Ø¯ Ø¶Ø±Ø±: {format_price(stop)}\n"
    txt += f"â± ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ…: {tf.upper()}\n"
    txt += f"ğŸ“Œ Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„: {analysis_type}\n"
    txt += f"ğŸ“ RRR: {rrr:.2f}"

    if reason:
        txt += f"\nğŸ” Ø¯Ù„ÛŒÙ„: {reason}"
        if "fibo" in str(reason).lower():
            txt += "\nğŸ§­ Ø¯Ø§ÛŒÙˆØ±Ú˜Ù†Ø³ + ÙÛŒØ¨ÙˆÙ†Ø§Ú†ÛŒ"

    return txt

def build_candles(df, tf):
    """
    Ø³Ø§Ø®Øª Ú©Ù†Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø± Ø§Ø³Ø§Ø³ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø§Ù†ØªØ®Ø§Ø¨ÛŒ.
    """
    try:
        rule = {"30min": "30min", "1h": "1h", "2h": "2h", "4h": "4h"}.get(tf)
        if not rule:
            return None

        o = df["Open"].resample(rule).first()
        h = df["High"].resample(rule).max()
        l = df["Low"].resample(rule).min()
        c = df["Close"].resample(rule).last()
        vol = df["Volume"].resample(rule).sum() if "Volume" in df.columns else None

        df_new = pd.DataFrame({"Open": o, "High": h, "Low": l, "Close": c})
        if vol is not None:
            df_new["Volume"] = vol

        return df_new.dropna()
    except Exception:
        return None

# ================== Ø¨Ø®Ø´ Û¶: Ø±Ø¬ÛŒØ³ØªØ±ÛŒØŒ Ø´Ù†Ø§Ø³Ù‡ Ø³ÛŒÚ¯Ù†Ø§Ù„ØŒ Ù¾Ø³â€ŒØ§Ø²ØµØ¯ÙˆØ± Ùˆ Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ ==================
SIX_HOURS = 6 * 3600  # Ú†Ø±Ø®Ù‡ Ø³Ø±Ø§Ø³Ø±ÛŒ Ø¶Ø¯Ø§Ø³Ù¾Ù… Ø¨Ø±Ø§ÛŒ Ù‡Ø± Ú©ÙˆÛŒÙ†

@dataclass
class SignalMetaAudit:
    coin_id: str
    side: str
    timeframe: str
    entry: float
    stop: float
    targets: List[float]
    rrr: float
    analysis_type: str
    data_source: str

@dataclass
class PostStatus:
    status: str        # "âœ… Target1", "âŒ Ø¨Ø§Ø·Ù„â€ŒØ´Ø¯Ù‡", "âš ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ", "âœ… ØªØ£ÛŒÛŒØ¯ Ø´Ø¯"
    reason: Optional[str] = None
    ts: float = field(default_factory=time.time)

class SignalRegistry:
    def __init__(self):
        self.last_issuance_ts_per_coin: Dict[str, float] = {}
        self.last_candle_fp: Dict[Tuple[str, str], str] = {}
        self.post_status: Dict[str, PostStatus] = {}
        self.active_signals: Dict[str, SignalMetaAudit] = {}

    def can_issue_6h(self, coin_id: str, now_ts: Optional[float] = None) -> Tuple[bool, str]:
        now_ts = now_ts or time.time()
        last = self.last_issuance_ts_per_coin.get(coin_id)
        if last is None or (now_ts - last) >= SIX_HOURS:
            return True, "OK"
        wait = int(SIX_HOURS - (now_ts - last))
        return False, f"â³ Ù‡Ù†ÙˆØ² {wait} Ø«Ø§Ù†ÛŒÙ‡ ØªØ§ Ú†Ø±Ø®Ù‡ Û¶ Ø³Ø§Ø¹ØªÙ‡ Ø¨Ø§Ù‚ÛŒâ€ŒØ³Øª"

    def mark_issued(self, coin_id: str, now_ts: Optional[float] = None):
        self.last_issuance_ts_per_coin[coin_id] = now_ts or time.time()

    def is_same_candle(self, coin_id: str, timeframe: str, candle_fp: str) -> bool:
        key = (coin_id, timeframe)
        last_fp = self.last_candle_fp.get(key)
        if last_fp == candle_fp:
            return True
        self.last_candle_fp[key] = candle_fp
        return False

    def set_post_status(self, signal_id: str, status: str, reason: Optional[str] = None):
        self.post_status[signal_id] = PostStatus(status=status, reason=reason)

def make_signal_id(coin_id: str, tf: str, entry: float, ts_iso: str) -> str:
    disp = symbol_display.get(coin_id, coin_id.upper())
    return f"{disp}-{tf}-{format_price(entry)}-{ts_iso}"

def rate_signal(has_confirmation: bool,
                near_key_level: bool,
                breakout_with_volume: bool,
                wyckoff_ok: bool) -> Tuple[int, List[str], str]:
    stars = 3
    notes: List[str] = []

    if has_confirmation:
        stars += 1
    else:
        notes.append("Ø¹Ø¯Ù… Ú©Ù†Ø¯Ù„ ØªØ£ÛŒÛŒØ¯ÛŒÙ‡")

    if breakout_with_volume:
        stars += 1
    else:
        notes.append("Ø­Ø¬Ù… Ø´Ú©Ø³Øª Ú©Ø§ÙÛŒ Ù†ÛŒØ³Øª")

    if near_key_level:
        stars -= 1
        notes.append("Ù†Ø²Ø¯ÛŒÚ©ÛŒ Ø¨Ù‡ Ø³Ø·Ø­ Ú©Ù„ÛŒØ¯ÛŒ â†’ Ø§Ø­ØªÙ…Ø§Ù„ Ø´Ú©Ø§Ø± Ù†Ù‚Ø¯ÛŒÙ†Ú¯ÛŒ")

    if not wyckoff_ok:
        stars -= 1
        notes.append("ÙˆØ§ÛŒÚ©ÙˆÙ Ù†Ø§Ø³Ø§Ø²Ú¯Ø§Ø±")

    stars = max(1, min(5, stars))
    label = "âŒ Ø¨Ø§Ø·Ù„â€ŒØ´Ø¯Ù‡" if stars <= 2 and not has_confirmation else \
            ("âœ… Ù…Ø¹ØªØ¨Ø±" if stars >= 4 and has_confirmation else "âš ï¸ Ù¾Ø±Ø±ÛŒØ³Ú©")

    return stars, notes, label

def evaluate_post_status(current_price: float,
                         side: str,
                         stop: float,
                         t1: float,
                         confirmation_after_issue: bool) -> Tuple[str, Optional[str]]:
    if side.lower() == "buy":
        if current_price <= stop:
            return "âŒ Ø¨Ø§Ø·Ù„â€ŒØ´Ø¯Ù‡", "Ø§Ø³ØªØ§Ù¾ ÙØ¹Ø§Ù„ Ø´Ø¯"
        if current_price >= t1:
            return "âœ… Target1", "ØªØ§Ø±Ú¯Øª Ø§ÙˆÙ„ ÙØ¹Ø§Ù„ Ø´Ø¯"
    else:
        if current_price >= stop:
            return "âŒ Ø¨Ø§Ø·Ù„â€ŒØ´Ø¯Ù‡", "Ø§Ø³ØªØ§Ù¾ ÙØ¹Ø§Ù„ Ø´Ø¯"
        if current_price <= t1:
            return "âœ… Target1", "ØªØ§Ø±Ú¯Øª Ø§ÙˆÙ„ ÙØ¹Ø§Ù„ Ø´Ø¯"

    if confirmation_after_issue:
        return "âœ… ØªØ£ÛŒÛŒØ¯ Ø´Ø¯", "Ú©Ù†Ø¯Ù„ ØªØ£ÛŒÛŒØ¯ÛŒÙ‡ Ø¨Ø¹Ø¯ Ø§Ø² ØµØ¯ÙˆØ± Ø´Ú©Ù„ Ú¯Ø±ÙØª"

    return "âš ï¸ Ø¯Ø± Ø­Ø§Ù„ Ø¨Ø±Ø±Ø³ÛŒ", None

def score_classic_signal(rrr_ok: bool,
                         volume_ok: bool,
                         candle_ok: bool,
                         aligned_ok: bool,
                         ema_ok: bool):
    """
    Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„ Ú©Ù„Ø§Ø³ÛŒÚ©:
    - 3 Ø´Ø±Ø· â†’ âš ï¸ Ù¾Ø±Ø±ÛŒØ³Ú©
    - 4 Ø´Ø±Ø· â†’ ğŸŸ¡ Ù…ØªØ¹Ø§Ø¯Ù„
    - 5 Ø´Ø±Ø· â†’ ğŸŸ¢ Ù‚ÙˆÛŒ
    - Ú©Ù…ØªØ± Ø§Ø² 3 Ø´Ø±Ø· â†’ Ø§Ø±Ø³Ø§Ù„ Ù†Ø´ÙˆØ¯
    """
    conditions = {
        "RRR â‰¥ 2.5": rrr_ok,
        "Ø­Ø¬Ù… Ø´Ú©Ø³Øª Ú©Ø§ÙÛŒ": volume_ok,
        "Ú©Ù†Ø¯Ù„ ØªØ£ÛŒÛŒØ¯ÛŒÙ‡": candle_ok,
        "Ù‡Ù…â€ŒØ¬Ù‡ØªÛŒ ØªØ§ÛŒÙ…â€ŒÙØ±ÛŒÙ… Ø¨Ø²Ø±Ú¯â€ŒØªØ±": aligned_ok,
        "Ù…ÙˆÙ‚Ø¹ÛŒØª EMA/MA": ema_ok
    }

    passed = [k for k, v in conditions.items() if v]
    failed = [k for k, v in conditions.items() if not v]
    score = len(passed)

    if score >= 5:
        return 5, "ğŸŸ¢ Ù‚ÙˆÛŒ", failed
    elif score == 4:
        return 4, "ğŸŸ¡ Ù…ØªØ¹Ø§Ø¯Ù„", failed
    elif score == 3:
        return 3, "âš ï¸ Ù¾Ø±Ø±ÛŒØ³Ú©", failed
    else:
        return None, None, None

# ================== Ø¨Ø®Ø´ Û·: Ù¾Ø§ÛŒØ¯Ø§Ø±Ø³Ø§Ø²ÛŒ last_signals ==================
load_last_signals()

# ================== Ø¨Ø®Ø´ Û·/Û²: Ù…Ø¯ÛŒØ±ÛŒØª Ù„Ø§Ú¯ Ù…Ø¯Ø§ÙˆÙ… ==================
LOG_BASE_NAME = "signals"
LOG_EXT = ".csv"
LOG_DIR = "logs"
MAX_LINES_PER_FILE = 5000

def ensure_log_dir():
    if not os.path.exists(LOG_DIR):
        os.makedirs(LOG_DIR)

def get_continuous_log_path():
    ensure_log_dir()
    return os.path.join(LOG_DIR, f"{LOG_BASE_NAME}{LOG_EXT}")

def get_next_part_path(current_path):
    ensure_log_dir()
    base = os.path.splitext(os.path.basename(current_path))[0]
    ext = os.path.splitext(current_path)[1]
    if "_part" in base:
        prefix, part = base.split("_part")
        try:
            n = int(part)
            return os.path.join(LOG_DIR, f"{prefix}_part{n+1}{ext}")
        except ValueError:
            return os.path.join(LOG_DIR, f"{LOG_BASE_NAME}_part2{ext}")
    else:
        return os.path.join(LOG_DIR, f"{LOG_BASE_NAME}_part2{ext}")

def init_continuous_log(path):
    ensure_log_dir()
    if not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            # Ù‡Ø¯Ø± Ù‡Ù…Ø§Ù‡Ù†Ú¯ Ø¨Ø§ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§
            f.write("timestamp,symbol,signal,entry,stop,target1,target2,target3,rrr,tf,analysis,data_source,reason,result\n")

def append_log_line_continuous(line, path=None):
    if path is None:
        path = get_continuous_log_path()
    init_continuous_log(path)

    with open(path, "a", encoding="utf-8") as f:
        f.write(line + "\n")

    try:
        with open(path, "r", encoding="utf-8") as f:
            lines = f.readlines()
    except Exception:
        return

    if len(lines) > MAX_LINES_PER_FILE:
        next_path = get_next_part_path(path)
        with open(next_path, "w", encoding="utf-8") as nf:
            nf.writelines(lines[:1])  # Ù‡Ø¯Ø±
        print(f"â„¹ï¸ Ù„Ø§Ú¯ Ø§Ø² Ø­Ø¯ {MAX_LINES_PER_FILE} Ø®Ø· Ú¯Ø°Ø´Øª. Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø±: {next_path}")

        # ================== Ø¨Ø®Ø´ Û·/Û³: Ù¾ÛŒØ§Ù… Ø§Ù†Ú¯ÛŒØ²Ø´ÛŒ Ø¨Ø¹Ø¯ Ø§Ø² Û² Ø³Ø§Ø¹Øª ==================
last_signal_time = None

def update_last_signal_time():
    global last_signal_time
    last_signal_time = now_dt()

def check_motivation_message():
    global last_signal_time
    if last_signal_time is None:
        last_signal_time = now_dt()
        return

    diff = now_dt() - last_signal_time
    if diff.total_seconds() >= 2 * 3600:  # Û² Ø³Ø§Ø¹Øª
        msg = get_random_motivation()
        send_signal(f"ğŸŒŸ {msg}")   # â† Ø­Ø§Ù„Ø§ Ù‡Ù… Ú©Ø§Ù†Ø§Ù„ Ù‡Ù… Ú†Øª Ø®ØµÙˆØµÛŒ
        last_signal_time = now_dt()

def get_random_motivation():
    motivations = [
        "Ù‡Ø± Ø±ÙˆØ² ÛŒÚ© Ù‚Ø¯Ù… Ú©ÙˆÚ†Ú© Ù‡Ù… Ù¾ÛŒØ´Ø±ÙØª Ø§Ø³Øª.",
        "ÛŒØ§Ø¯ Ø¨Ú¯ÛŒØ±ØŒ ØªÙ„Ø§Ø´ Ú©Ù†ØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯Ù‡.",
        "Ù…ÙˆÙÙ‚ÛŒØª Ø³Ù‡Ù… Ú©Ø³Ø§Ù†ÛŒ Ø§Ø³Øª Ú©Ù‡ ØµØ¨Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù†Ø¯.",
        "Ø±ÙˆÛŒØ§Ù‡Ø§ØªÙˆ Ø¨Ø§ÙˆØ± Ú©Ù†ØŒ Ø¨Ø¹Ø¯ Ø¯Ù†Ø¨Ø§Ù„Ø´ Ø¨Ø±Ùˆ.",
        "Ù‡Ø± Ø³Ø®ØªÛŒ Ù¾Ù„ÛŒ Ø§Ø³Øª Ø¨Ù‡ Ø³Ù…Øª Ø±Ø´Ø¯.",
        "Ø§Ù…Ø±ÙˆØ² Ø¨Ù‡ØªØ±ÛŒÙ† Ø²Ù…Ø§Ù† Ø´Ø±ÙˆØ¹ Ø§Ø³Øª.",
        "Ù‡ÛŒÚ† ØªÙ„Ø§Ø´ÛŒ Ø¨ÛŒâ€ŒØ«Ù…Ø± Ù†Ù…ÛŒâ€ŒÙ…Ø§Ù†Ø¯."
    ]
    return random.choice(motivations)

    # ================== Ø¨Ø®Ø´ Û¸/Û±a: Ø¯Ø§ÛŒÙˆØ±Ú˜Ù†Ø³ØŒ ÙÛŒØ¨ÙˆØŒ Ù„Ø§Ú¯ØŒ Ø±Ø¬ÛŒØ³ØªØ±ÛŒ ==================
def check_divergence(df, rsi_period=14, lookback=30, pivot_lookback=5, threshold=0.5):
    if df is None or df.empty or len(df) < lookback:
        return None

    close = df["Close"].iloc[-lookback:]
    rsi = ta.momentum.RSIIndicator(df["Close"], rsi_period).rsi().iloc[-lookback:]

    def find_pivots(series, lb):
        pivots_high, pivots_low = [], []
        for i in range(lb, len(series) - lb):
            window = series[i - lb:i + lb + 1]
            if series[i] == window.max():
                pivots_high.append((i, series[i]))
            if series[i] == window.min():
                pivots_low.append((i, series[i]))
        return pivots_high, pivots_low

    price_highs, price_lows = find_pivots(close.values, pivot_lookback)
    rsi_highs, rsi_lows = find_pivots(rsi.values, pivot_lookback)

    if len(price_highs) < 2 or len(price_lows) < 2:
        return None

    ph1, ph2 = price_highs[-2], price_highs[-1]
    pl1, pl2 = price_lows[-2], price_lows[-1]
    rh1, rh2 = rsi_highs[-2], rsi_highs[-1] if len(rsi_highs) >= 2 else (None, None)
    rl1, rl2 = rsi_lows[-2], rsi_lows[-1] if len(rsi_lows) >= 2 else (None, None)

    if pl2[1] < pl1[1] and rl2 and rl1 and rl2[1] > rl1[1] + threshold:
        return "regular_bull"
    if ph2[1] > ph1[1] and rh2 and rh1 and rh2[1] < rh1[1] - threshold:
        return "regular_bear"
    if pl2[1] > pl1[1] and rl2 and rl1 and rl2[1] < rl1[1] - threshold:
        return "hidden_bull"
    if ph2[1] < ph1[1] and rh2 and rh1 and rh2[1] > rh1[1] + threshold:
        return "hidden_bear"

    return None


def is_fibo_zone(df, level=0.618, tolerance=0.01):
    if df is None or df.empty:
        return False, level
    price = df["Close"].iloc[-1]
    high, low = df["High"].max(), df["Low"].min()
    fibo_price = high - (high - low) * level
    return abs(price - fibo_price) <= (price * tolerance), level


def log_signal(coin_id, signal, entry, stop, targets, rrr, tf, analysis_type, data_source, reason=None, result=""):
    t1 = format_price(targets[0]) if targets and len(targets) > 0 else ""
    t2 = format_price(targets[1]) if targets and len(targets) > 1 else ""
    t3 = format_price(targets[2]) if targets and len(targets) > 2 else ""
    timestamp = now_dt().isoformat()
    symbol_disp = symbol_display.get(coin_id, coin_id.upper())
    rrr_str = f"{rrr:.2f}" if rrr is not None else ""

    entry_str = format_price(entry) if entry is not None else ""
    stop_str = format_price(stop) if stop is not None else ""
    reason_str = reason or ""

    line = ",".join([
        timestamp,
        symbol_disp,
        signal or "",
        entry_str,
        stop_str,
        t1,
        t2,
        t3,
        rrr_str,
        tf or "",
        analysis_type or "",
        data_source or "",
        reason_str,
        result or ""
    ])
    append_log_line_continuous(line)
    update_last_signal_time()


# ---------- Ø±Ø¬ÛŒØ³ØªØ±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ ----------
registry = SignalRegistry()


# ---------- ÙÛŒÙ„ØªØ± MA20/MA50 ----------
def ma_filter(df, side):
    ma20 = df["Close"].rolling(20).mean().iloc[-1]
    ma50 = df["Close"].rolling(50).mean().iloc[-1]
    price = df["Close"].iloc[-1]

    if side == "buy":
        return price > ma20 and ma20 > ma50
    elif side == "sell":
        return price < ma20 and ma20 < ma50
    return False

    # ================== Ø¨Ø®Ø´ Û¸/Û±b: Ù…Ø¯ÛŒØ±ÛŒØª Ø°Ø®ÛŒØ±Ù‡ Ø¢Ø®Ø±ÛŒÙ† Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ (Ù†Ø³Ø®Ù‡ Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡) ==================
import json, os

LAST_SIGNALS_FILE = "last_signals.json"
last_signals = {}

def save_last_signals():
    try:
        # Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø±Ùˆ Ø¨Ù‡ Ø±Ø´ØªÙ‡ ØªØ¨Ø¯ÛŒÙ„ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
        serializable = {str(k): v for k, v in last_signals.items()}
        with open(LAST_SIGNALS_FILE, "w", encoding="utf-8") as f:
            json.dump(serializable, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ last_signals:", e)

def load_last_signals():
    global last_signals
    if os.path.exists(LAST_SIGNALS_FILE):
        try:
            with open(LAST_SIGNALS_FILE, "r", encoding="utf-8") as f:
                data = json.load(f)
            # Ú©Ù„ÛŒØ¯Ù‡Ø§ Ø±Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ø¨Ù‡ tuple Ø¨Ø±Ú¯Ø±Ø¯ÙˆÙ†ÛŒÙ… (coin_id, tf)
            last_signals = {}
            for k, v in data.items():
                if "_" in k:
                    coin_id, tf = k.split("_", 1)
                    last_signals[(coin_id, tf)] = v
                else:
                    last_signals[k] = v
        except Exception as e:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ last_signals:", e)
            last_signals = {}
    else:
        last_signals = {}

        # ================== Ø¨Ø®Ø´ Û¸/Û²a: ØªØ§Ø¨Ø¹ analyze_coin ==================
def analyze_coin(coin_id, now):
    signals = {}
    df_base, data_source = fetch_data(coin_id, days=30)
    if df_base is None or df_base.empty:
        log_signal(coin_id, "none", None, None, None, None,
                   "", "", data_source, reason="No data")
        return {}

    for tf in TIMEFRAMES:
        df_tf = build_candles(df_base, tf)
        if df_tf is None or df_tf.empty or "Close" not in df_tf.columns or len(df_tf["Close"]) == 0:
            continue

        sig_ind = get_indicator_signal(df_tf)
        sig_cls = get_classic_signal(df_tf) if tf in ["2h", "4h"] else None
        score_cls = None
        if sig_cls:
            score_cls, _, _ = score_classic_signal(True, True, True, True, True)

        div = check_divergence(df_tf)
        if div:
            in_618, lvl_618 = is_fibo_zone(df_tf, 0.618)
            in_1618, lvl_1618 = is_fibo_zone(df_tf, 1.618)
            if in_618 or in_1618:
                fibo_label = f"{div}_fibo_{lvl_618 if in_618 else lvl_1618}"
                if div.endswith("bull"):
                    signals[tf] = ("buy", "Ø¯Ø§ÛŒÙˆØ±Ú˜Ù†Ø³+ÙÛŒØ¨Ùˆ", df_tf, fibo_label, score_cls, data_source)
                elif div.endswith("bear"):
                    signals[tf] = ("sell", "Ø¯Ø§ÛŒÙˆØ±Ú˜Ù†Ø³+ÙÛŒØ¨Ùˆ", df_tf, fibo_label, score_cls, data_source)

        if tf not in signals:
            if sig_ind and sig_cls and sig_ind == sig_cls:
                signals[tf] = (sig_ind, "Ù‚ÙˆÛŒ (Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ + Ú©Ù„Ø§Ø³ÛŒÚ©)", df_tf, None, score_cls, data_source)
            elif sig_cls and score_cls is not None and score_cls >= 4:
                signals[tf] = (sig_cls, "Ú©Ù„Ø§Ø³ÛŒÚ© (Ù…ØªØ¹Ø§Ø¯Ù„ ÛŒØ§ Ø§ÛŒØ¯Ù‡â€ŒØ¢Ù„)", df_tf, None, score_cls, data_source)
            elif sig_ind:
                signals[tf] = (sig_ind, "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ", df_tf, None, score_cls, data_source)

    return signals

    # ================== Ø¨Ø®Ø´ Û¸/Û²b: ØªØ§Ø¨Ø¹ run_once ==================
def run_once():
    global last_signal_time

    print("â–¶ï¸ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª...")
    now = now_dt()
    total = len(SYMBOLS)
    with_data, no_data = 0, 0
    no_data_list, issued_pairs = [], []
    used_symbols = set()
    count_strong = 0
    count_classic = 0
    count_indicator = 0
    count_rejected = 0
    any_signal = False

    # --- Ù¾ÛŒÚ¯ÛŒØ±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ ---
    try:
        for sig_id, meta in list(registry.active_signals.items()):
            df_now, _src = fetch_data(meta.coin_id, days=3)
            if df_now is None or df_now.empty or "Close" not in df_now.columns or len(df_now["Close"]) == 0:
                continue
            current_price = float(df_now["Close"].iloc[-1])

            df_1h = build_candles(df_now, "1h")
            conf = False
            if df_1h is not None and not df_1h.empty:
                conf_sig = get_indicator_signal(df_1h) or get_classic_signal(df_1h)
                conf = (conf_sig == meta.side)

            status, reason = evaluate_post_status(current_price, meta.side, meta.stop, meta.targets[0], conf)
            registry.set_post_status(sig_id, status, reason)
            log_signal(meta.coin_id, meta.side, meta.entry, meta.stop, meta.targets, meta.rrr,
                       meta.timeframe, meta.analysis_type, meta.data_source,
                       reason=f"Post-status: {status}" + (f" ({reason})" if reason else ""))

            if status == "âŒ Ø¨Ø§Ø·Ù„â€ŒØ´Ø¯Ù‡":
                last_key = f"{meta.coin_id}_{meta.timeframe}"
                if last_key in last_signals:
                    last_signals[last_key]["status"] = "stopped"
                    save_last_signals()
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„:", e)

    # --- ØªÙˆÙ„ÛŒØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ ---
    for coin_id in SYMBOLS:
        try:
            signals = analyze_coin(coin_id, now)
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± analyze_coin {coin_id}:", e)
            no_data += 1
            no_data_list.append(coin_id)
            continue

        if not signals:
            no_data += 1
            no_data_list.append(coin_id)
            continue
        else:
            with_data += 1

        # --- Ø§Ù†ØªØ®Ø§Ø¨ Ùˆ ØµØ¯ÙˆØ± Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù†Ù‡Ø§ÛŒÛŒ ---
        for tf in reversed(TIMEFRAMES):
            if tf not in signals:
                continue

            sig, analysis_type, df_tf, sig_reason, score_cls, data_source = signals[tf]

            if df_tf is None or df_tf.empty or "Close" not in df_tf.columns or len(df_tf["Close"]) == 0:
                count_rejected += 1
                continue

            try:
                last_ts = df_tf.index[-1]
                entry = float(df_tf["Close"].iloc[-1])
            except Exception:
                count_rejected += 1
                continue

            stop, targets, rrr = calculate_sl_tp(entry, sig, df_tf)
            if not stop or targets is None or len(targets) == 0 or rrr is None:
                log_signal(coin_id, "none", None, None, None, None,
                           tf, analysis_type, data_source,
                           reason="Invalid SL/TP/RRR")
                count_rejected += 1
                continue

            # --- Ø¶Ø¯ØªÚ©Ø±Ø§Ø± Û¶ Ø³Ø§Ø¹ØªÙ‡ ---
            prev = last_signals.get(f"{coin_id}_{tf}")
            if prev:
                try:
                    prev_time = datetime.fromisoformat(prev.get("time", ""))
                    if prev_time and prev_time.tzinfo is None:
                        prev_time = prev_time.replace(tzinfo=timezone.utc)
                except Exception:
                    prev_time = None

                if prev_time is None:
                    prev_time = now

                diff_hours = (now - prev_time).total_seconds() / 3600.0
                last_status = prev.get("status", "active")

                if diff_hours < 6 and last_status != "stopped":
                    log_signal(
                        coin_id, "none", entry, stop, targets, rrr,
                        tf, analysis_type, data_source,
                        reason=f"Duplicate within 6h window (last {diff_hours:.2f}h ago)"
                    )
                    count_rejected += 1
                    continue

            # --- Ø§Ù…ØªÛŒØ§Ø²Ø¯Ù‡ÛŒ Ú©Ù„Ø§Ø³ÛŒÚ© + ÙÛŒÙ„ØªØ± MA20/50 ---
            if "Ú©Ù„Ø§Ø³ÛŒÚ©" in analysis_type:
                if score_cls is None or score_cls < 4:
                    log_signal(coin_id, "none", entry, stop, targets, rrr,
                               tf, analysis_type, data_source,
                               reason="Classic score < 4 (Ø±Ø¯ Ø´Ø¯)")
                    count_rejected += 1
                    continue

                if not ma_filter(df_tf, sig):
                    log_signal(coin_id, "none", entry, stop, targets, rrr,
                               tf, analysis_type, data_source,
                               reason="MA20/50 filter not passed")
                    count_rejected += 1
                    continue

                sig_reason = (sig_reason or "") + f" | ClassicScore={score_cls}"

            # --- Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ùˆ Ø§Ø±Ø³Ø§Ù„ ---
            msg = format_signal(coin_id, sig, entry, targets, stop, tf,
                                analysis_type, rrr, reason=sig_reason)
            send_signal(msg)
            log_signal(coin_id, sig, entry, stop, targets, rrr,
                       tf, analysis_type, data_source, reason=sig_reason)

            registry.mark_issued(coin_id)

            # âœ… Ø§ØµÙ„Ø§Ø­ Ú©Ù„ÛŒØ¯: Ø±Ø´ØªÙ‡â€ŒØ§ÛŒ Ø¨Ù‡ Ø¬Ø§ÛŒ tuple
            last_signals[f"{coin_id}_{tf}"] = {
                "last_ts": last_ts.isoformat(),
                "direction": sig,
                "time": now.isoformat(),
                "status": "active"
            }
            save_last_signals()

            sig_id = make_signal_id(coin_id, tf, entry, last_ts.isoformat())
            registry.active_signals[sig_id] = SignalMetaAudit(
                coin_id=coin_id, side=sig, timeframe=tf, entry=entry,
                stop=stop, targets=targets, rrr=rrr,
                analysis_type=analysis_type, data_source=data_source
            )

            issued_pairs.append(f"{symbol_display.get(coin_id, coin_id.upper())}-{tf}")
            if "Ù‚ÙˆÛŒ" in analysis_type:
                count_strong += 1
            elif "Ú©Ù„Ø§Ø³ÛŒÚ©" in analysis_type:
                count_classic += 1
            elif "Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ" in analysis_type:
                count_indicator += 1

            any_signal = True
            used_symbols.add(coin_id)
            break  # Ù¾Ø³ Ø§Ø² ØµØ¯ÙˆØ± ÛŒÚ© Ø³ÛŒÚ¯Ù†Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ú©ÙˆÛŒÙ†ØŒ Ø¨Ù‡ Ú©ÙˆÛŒÙ† Ø¨Ø¹Ø¯ÛŒ Ø¨Ø±Ùˆ

    # --- Ú¯Ø²Ø§Ø±Ø´ Ø®Ù„Ø§ØµÙ‡ ---
    print("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø§Ø¬Ø±Ø§ÛŒ Ù†ÙˆØ¨Øª:")
    print(f"Ú©Ù„ Ø¬ÙØªâ€ŒÙ‡Ø§: {total}")
    print(f"Ø¨Ø§ Ø¯Ø§Ø¯Ù‡: {with_data}, Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡: {no_data}")
    print(f"Ø³ÛŒÚ¯Ù†Ø§Ù„ Ù‚ÙˆÛŒ: {count_strong}, Ú©Ù„Ø§Ø³ÛŒÚ©: {count_classic}, Ø§Ù†Ø¯ÛŒÚ©Ø§ØªÙˆØ±ÛŒ: {count_indicator}")
    print(f"Ø±Ø¯ Ø´Ø¯Ù‡: {count_rejected}")
    if issued_pairs:
        print("âœ… Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ÛŒ ØµØ§Ø¯Ø± Ø´Ø¯Ù‡:", ", ".join(issued_pairs))
    if no_data_list:
        print("âš ï¸ Ø¨Ø¯ÙˆÙ† Ø¯Ø§Ø¯Ù‡:", ", ".join(no_data_list))

    # --- Ù¾ÛŒØ§Ù… Ø§Ù†Ú¯ÛŒØ²Ø´ÛŒ Ø¯Ø± ØµÙˆØ±Øª Ù†Ø¨ÙˆØ¯ Ø³ÛŒÚ¯Ù†Ø§Ù„ ---
    if not any_signal:
        send_motivation_message()

    print("â¹ Ù¾Ø§ÛŒØ§Ù† Ø§Ø¬Ø±Ø§ÛŒ Ø±Ø¨Ø§Øª.")

    # ================== Ø¨Ø®Ø´ Û¸/Û³: Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù‡ÙØªÚ¯ÛŒØŒ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ø§ Ø¬Ø²Ø¦ÛŒØ§Øª ==================

def load_log_df():
    """
    Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù„Ø§Ú¯ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ù†ÙˆØ§Ù† DataFrame.
    Ø§Ù†ØªØ¸Ø§Ø± Ø³ØªÙˆÙ†â€ŒÙ‡Ø§:
    timestamp,symbol,signal,entry,stop,t1,t2,t3,rrr,tf,analysis_type,source,reason,result
    """
    try:
        df = pd.read_csv(LOG_FILE_PATH)
        df["timestamp"] = pd.to_datetime(df["timestamp"], errors="coerce", utc=True)
        # Ù‡Ù…â€ŒÙ†Ø§Ù…â€ŒØ³Ø§Ø²ÛŒ Ø§Ú¯Ø± Ø³ØªÙˆÙ†ÛŒ Ù…ØªÙØ§ÙˆØª Ø¨ÙˆØ¯
        if "analysis" in df.columns and "analysis_type" not in df.columns:
            df = df.rename(columns={"analysis": "analysis_type"})
        return df
    except Exception:
        return None


def build_summary_message(title, df):
    """
    Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù… Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§ Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ + Ø¬Ø²Ø¦ÛŒØ§Øª Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒØ´Ø¯Ù‡.
    """
    if df is None or df.empty:
        return f"{title}\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    # Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²
    for col in ["result", "symbol", "analysis_type", "tf", "rrr"]:
        if col not in df.columns:
            df[col] = "" if col != "rrr" else pd.Series(dtype=float)

    res = df["result"].fillna("")
    is_active = (res == "") | (res == "active")
    is_hit = (res == "hit_target")
    is_stopped = (res == "stopped")

    total = len(df)
    hit = int(is_hit.sum())
    stopped = int(is_stopped.sum())
    active = int(is_active.sum())

    avg_rrr = pd.to_numeric(df["rrr"], errors="coerce").mean()
    winrate = (hit / (hit + stopped) * 100) if (hit + stopped) > 0 else 0.0

    lines = []
    if hit > 0:
        lines.append("âœ… ØªØ§Ø±Ú¯Øªâ€ŒØ®ÙˆØ±Ø¯Ù‡â€ŒÙ‡Ø§:")
        for _, row in df[is_hit].iterrows():
            lines.append(f"- {row.get('symbol','?')} | {row.get('analysis_type','?')} | {row.get('tf','?')}")

    if stopped > 0:
        lines.append("âŒ Ø§Ø³ØªØ§Ù¾â€ŒØ®ÙˆØ±Ø¯Ù‡â€ŒÙ‡Ø§:")
        for _, row in df[is_stopped].iterrows():
            lines.append(f"- {row.get('symbol','?')} | {row.get('analysis_type','?')} | {row.get('tf','?')}")

    if active > 0:
        lines.append("ğŸ”µ Ø¯Ø± Ø¬Ø±ÛŒØ§Ù†:")
        for _, row in df[is_active].iterrows():
            lines.append(f"- {row.get('symbol','?')} | {row.get('analysis_type','?')} | {row.get('tf','?')}")

    details_text = "\n".join(lines) if lines else "Ù‡ÛŒÚ† Ø¬Ø²Ø¦ÛŒØ§ØªÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    msg = (
        f"{title}\n"
        f"ğŸ§® Ú©Ù„ Ø³ÛŒÚ¯Ù†Ø§Ù„â€ŒÙ‡Ø§: {total}\n"
        f"âœ… Ù‡Ø¯Ùâ€ŒØ®ÙˆØ±Ø¯Ù‡: {hit} | âŒ Ø§Ø³ØªØ§Ù¾: {stopped} | ğŸ”µ Ø¯Ø± Ø¬Ø±ÛŒØ§Ù†: {active}\n"
        f"ğŸ† ÙˆÛŒÙ†â€ŒØ±ÛŒØª: {winrate:.1f}% | ğŸ“ Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† RRR: {avg_rrr:.2f}\n\n"
        f"{details_text}"
    )
    return msg


def build_daily_message():
    df = load_log_df()
    if df is None or df.empty:
        return "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    cutoff = pd.Timestamp.now(tz=timezone.utc) - pd.Timedelta(days=1)
    df_d = df[df["timestamp"] >= cutoff]
    msg = build_summary_message("ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡", df_d)
    append_report("daily", msg)
    return msg


def build_weekly_message():
    df = load_log_df()
    if df is None or df.empty:
        return "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    cutoff = pd.Timestamp.now(tz=timezone.utc) - pd.Timedelta(days=7)
    df_w = df[df["timestamp"] >= cutoff]
    msg = build_summary_message("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ", df_w)
    append_report("weekly", msg)
    return msg


def build_monthly_message():
    df = load_log_df()
    if df is None or df.empty:
        return "ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

    cutoff = pd.Timestamp.now(tz=timezone.utc) - pd.Timedelta(days=30)
    df_m = df[df["timestamp"] >= cutoff]
    msg = build_summary_message("ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡", df_m)
    append_report("monthly", msg)
    return msg

    # ================== Ø¨Ø®Ø´ :8/4 Ù…Ø¯ÛŒØ±ÛŒØª Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ (reports.csv) ================
REPORTS_BASE_NAME = "reports"
REPORTS_EXT = ".csv"
REPORTS_DIR = "logs"
MAX_REPORT_LINES = 5000

def ensure_reports_dir():
    if not os.path.exists(REPORTS_DIR):
        os.makedirs(REPORTS_DIR)

def get_reports_path():
    ensure_reports_dir()
    return os.path.join(REPORTS_DIR, f"{REPORTS_BASE_NAME}{REPORTS_EXT}")

def get_next_report_part(current_path):
    ensure_reports_dir()
    base = os.path.splitext(os.path.basename(current_path))[0]
    ext = os.path.splitext(current_path)[1]
    if "_part" in base:
        prefix, part = base.split("_part")
        try:
            n = int(part)
            return os.path.join(REPORTS_DIR, f"{prefix}_part{n+1}{ext}")
        except ValueError:
            return os.path.join(REPORTS_DIR, f"{REPORTS_BASE_NAME}_part2{ext}")
    else:
        return os.path.join(REPORTS_DIR, f"{REPORTS_BASE_NAME}_part2{ext}")

def init_reports_log(path):
    ensure_reports_dir()
    if not os.path.exists(path):
        with open(path, "w", encoding="utf-8") as f:
            f.write("timestamp,type,message\n")

def append_report(report_type: str, msg: str, path=None):
    if path is None:
        path = get_reports_path()
    init_reports_log(path)

    timestamp = now_dt().isoformat()
    line = f"{timestamp},{report_type},{json.dumps(msg, ensure_ascii=False)}"

    # Ù†ÙˆØ´ØªÙ† Ø¯Ø± ÙØ§ÛŒÙ„ ÙØ¹Ù„ÛŒ
    with open(path, "a", encoding="utf-8") as f:
        f.write(line + "\n")

    # Ø¨Ø±Ø±Ø³ÛŒ Ø·ÙˆÙ„ Ùˆ Ø§ÛŒØ¬Ø§Ø¯ Ù¾Ø§Ø±Øª Ø¨Ø¹Ø¯ÛŒ Ø¨Ø§ Ù‡Ø¯Ø± (Ø¨Ø±Ø§ÛŒ Ø®ÙˆØ§Ù†Ø¯Ù†â€ŒÙ‡Ø§ÛŒ Ø¨Ø¹Ø¯ÛŒ)
    try:
        with open(path, "r", encoding="utf-8") as f:
            lines = f.readlines()
        if len(lines) > MAX_REPORT_LINES:
            next_path = get_next_report_part(path)
            if not os.path.exists(next_path):
                with open(next_path, "w", encoding="utf-8") as nf:
                    nf.write(lines[0])  # ÙÙ‚Ø· Ù‡Ø¯Ø±
            print(f"â„¹ï¸ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø§Ø² Ø­Ø¯ {MAX_REPORT_LINES} Ø®Ø· Ú¯Ø°Ø´Øª. Ø§Ø¯Ø§Ù…Ù‡ Ø¯Ø±: {next_path}")
    except Exception:
        pass

def get_last_report(report_type: str):
    try:
        files = sorted([
            os.path.join(REPORTS_DIR, f) for f in os.listdir(REPORTS_DIR)
            if f.startswith(REPORTS_BASE_NAME) and f.endswith(REPORTS_EXT)
        ])
        if not files:
            return f"Ù‡ÛŒÚ† Ú¯Ø²Ø§Ø±Ø´ÛŒ Ø§Ø² Ù†ÙˆØ¹ {report_type} Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."

        # Ø§Ø² Ø¬Ø¯ÛŒØ¯ØªØ±ÛŒÙ† ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¹Ù‚Ø¨
        for path in reversed(files):
            df = pd.read_csv(path)
            if "type" not in df.columns or "message" not in df.columns:
                continue
            sel = df[df["type"] == report_type]
            if sel.empty:
                continue
            msg_raw = sel.iloc[-1]["message"]
            try:
                msg = json.loads(msg_raw)  # Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ json.dumps Ø´Ø¯Ù‡â€ŒØ§Ù†Ø¯
            except Exception:
                msg = str(msg_raw)
            return msg

        return f"Ù‡ÛŒÚ† Ú¯Ø²Ø§Ø±Ø´ÛŒ Ø§Ø² Ù†ÙˆØ¹ {report_type} Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."
    except Exception as e:
        return f"Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú¯Ø²Ø§Ø±Ø´ {report_type}: {e}"

# ================== Ø¨Ø®Ø´ Û¸/Ûµ: Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ Ø±ÙˆØ²Ø§Ù†Ù‡ØŒ Ù‡ÙØªÚ¯ÛŒ Ùˆ Ù…Ø§Ù‡Ø§Ù†Ù‡ ==================
from datetime import datetime, timedelta

# ÙÙ„Ú¯â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² ØªÚ©Ø±Ø§Ø± (ÙÙ‚Ø· ÛŒÚ©â€ŒØ¨Ø§Ø± Ø¯Ø± Ù‡Ø± Ù¾Ù†Ø¬Ø±Ù‡â€ŒÛŒ Ø²Ù…Ø§Ù†)
daily_done_today = False
weekly_done_this_week = False
monthly_done_this_month = False

def _in_nightly_window(now: datetime) -> bool:
    """
    Ø¨Ø§Ø²Ù‡ Ù…Ø¬Ø§Ø² Ø§Ø¬Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ: Ø§Ø² 00:20 ØªØ§ 02:00
    - 00:20 ØªØ§ 00:59
    - 01:00 ØªØ§ 01:59
    - 02:00 Ø¯Ù‚ÛŒÙ‚Ø§Ù‹ (Ø¨Ø±Ø§ÛŒ Ø¬Ø¨Ø±Ø§Ù† ØªØ£Ø®ÛŒØ±)
    """
    return ((now.hour == 0 and now.minute >= 20)
            or (now.hour == 1)
            or (now.hour == 2 and now.minute == 0))

def schedule_reports(now: datetime):
    global daily_done_today, weekly_done_this_week, monthly_done_this_month

    # ---------------- Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ ----------------
    # Ø¯ÛŒØ±ÙˆØ² Ø±Ø§ Ú¯Ø²Ø§Ø±Ø´ Ù…ÛŒâ€ŒÚ©Ù†Ø¯Ø› ÙÙ‚Ø· ÛŒÚ©â€ŒØ¨Ø§Ø± Ø¯Ø± Ø¨Ø§Ø²Ù‡ 00:20 ØªØ§ 02:00
    if _in_nightly_window(now) and not daily_done_today:
        try:
            yesterday = (now - timedelta(days=1)).date()

            # Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§ÛŒ Ø±ÙˆØ² Ù‚Ø¨Ù„
            daily_data = [
                row for row in load_reports()
                if datetime.strptime(row['date'], "%Y-%m-%d").date() == yesterday
            ]

            if daily_data:
                build_daily_report(daily_data, yesterday)
                print(f"âœ… [DAILY] Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ {yesterday} Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯ Ùˆ Ø¯Ø± reports.csv Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯.")
            else:
                print(f"âš ï¸ [DAILY] Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ {yesterday} Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ø› Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯.")

            daily_done_today = True
        except Exception as e:
            print("âŒ [DAILY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡:", e)

    # ---------------- Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ ----------------
    # Ø´Ù†Ø¨Ù‡ Ø¨Ø§Ù…Ø¯Ø§Ø¯ (weekday() == 5)Ø› Ú¯Ø²Ø§Ø±Ø´ Ø¨Ø§Ø²Ù‡ Ú©Ø§Ù…Ù„ ÛŒÚ©Ø´Ù†Ø¨Ù‡ ØªØ§ Ø¬Ù…Ø¹Ù‡â€ŒÛŒ Ù‡ÙØªÙ‡â€ŒÛŒ Ù‚Ø¨Ù„
    if (now.weekday() == 5) and _in_nightly_window(now) and not weekly_done_this_week:
        try:
            # Ø¬Ù…Ø¹Ù‡â€ŒÛŒ Ù‡Ù…ÛŒÙ† Ù‡ÙØªÙ‡ (Ø±ÙˆØ² Ù‚Ø¨Ù„Ù Ø´Ù†Ø¨Ù‡)
            last_week_end = (now - timedelta(days=1)).date()        # Friday
            # ÛŒÚ©Ø´Ù†Ø¨Ù‡â€ŒÛŒ Ù‡ÙØªÙ‡â€ŒÛŒ Ù‚Ø¨Ù„ (Ø´Ø±ÙˆØ¹ Ø¨Ø§Ø²Ù‡ 7 Ø±ÙˆØ²Ù‡)
            last_week_start = last_week_end - timedelta(days=6)     # Sunday â†’ Friday

            weekly_data = [
                row for row in load_reports()
                if last_week_start <= datetime.strptime(row['date'], "%Y-%m-%d").date() <= last_week_end
            ]

            if weekly_data:
                build_weekly_report(weekly_data, last_week_start, last_week_end)
                print(f"âœ… [WEEKLY] Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {last_week_start} ØªØ§ {last_week_end} Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
            else:
                print("âš ï¸ [WEEKLY] Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù‡ÙØªÙ‡ Ù‚Ø¨Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ø› Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯.")

            weekly_done_this_week = True
        except Exception as e:
            print("âŒ [WEEKLY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ:", e)

    # ---------------- Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ----------------
    # Ø§ÙˆÙ„ÛŒÙ† Ø±ÙˆØ² Ù…Ø§Ù‡ (day == 1)Ø› Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡ Ú©Ø§Ù…Ù„ Ù‚Ø¨Ù„ Ø¨Ø§ Ù…Ø­Ø§Ø³Ø¨Ù‡â€ŒÛŒ Ø¯Ù‚ÛŒÙ‚ ØªØ¹Ø¯Ø§Ø¯ Ø±ÙˆØ²Ù‡Ø§
    if (now.day == 1) and _in_nightly_window(now) and not monthly_done_this_month:
        try:
            # Ø¢Ø®Ø±ÛŒÙ† Ø±ÙˆØ² Ù…Ø§Ù‡ Ù‚Ø¨Ù„ = Ø±ÙˆØ² Ù‚Ø¨Ù„ Ø§Ø² Ø±ÙˆØ² Ø§ÙˆÙ„ Ù…Ø§Ù‡ Ø¬Ø§Ø±ÛŒ
            last_day_last_month = (now.replace(day=1) - timedelta(days=1)).date()
            # Ø§ÙˆÙ„ÛŒÙ† Ø±ÙˆØ² Ù…Ø§Ù‡ Ù‚Ø¨Ù„
            first_day_last_month = last_day_last_month.replace(day=1)

            monthly_data = [
                row for row in load_reports()
                if first_day_last_month <= datetime.strptime(row['date'], "%Y-%m-%d").date() <= last_day_last_month
            ]

            if monthly_data:
                build_monthly_report(monthly_data, first_day_last_month, last_day_last_month)
                print(f"âœ… [MONTHLY] Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ù‡ {first_day_last_month} ØªØ§ {last_day_last_month} Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯.")
            else:
                print("âš ï¸ [MONTHLY] Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø§Ù‡ Ù‚Ø¨Ù„ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯Ø› Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø³Ø§Ø®ØªÙ‡ Ù†Ø´Ø¯.")

            monthly_done_this_month = True
        except Exception as e:
            print("âŒ [MONTHLY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡:", e)
# ================== Ø¨Ø®Ø´ Û¸/Û¶: Ú¯Ø²Ø§Ø±Ø´ Ùˆ Ø¨Ø±Ø±Ø³ÛŒ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† ==================
import csv
from datetime import datetime

BTC_GAP_FILE = "btc_gaps.csv"

# ØªØ´Ø®ÛŒØµ Ú¯Ù¾
def detect_btc_gap(friday_close, sunday_open, threshold=0.002):
    """
    ØªØ´Ø®ÛŒØµ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ø¨ÛŒÙ† Ù‚ÛŒÙ…Øª Ø¨Ø³ØªÙ‡ Ø´Ø¯Ù† Ø¬Ù…Ø¹Ù‡ Ùˆ Ø¨Ø§Ø² Ø´Ø¯Ù† ÛŒÚ©Ø´Ù†Ø¨Ù‡
    threshold = 0.002 ÛŒØ¹Ù†ÛŒ 0.2 Ø¯Ø±ØµØ¯
    """
    diff = (sunday_open - friday_close) / friday_close
    if abs(diff) >= threshold:
        gap_type = "up" if diff > 0 else "down"
        return {
            "gap_type": gap_type,
            "gap_size": round(diff * 100, 2),
            "friday_close": friday_close,
            "sunday_open": sunday_open
        }
    return None

# Ø«Ø¨Øª Ú¯Ù¾ Ø¯Ø± ÙØ§ÛŒÙ„ Ø¬Ø¯Ø§
def log_btc_gap(gap_info):
    header = ["date", "gap_type", "gap_size", "friday_close", "sunday_open", "status", "fill_time"]
    file_exists = os.path.exists(BTC_GAP_FILE)

    with open(BTC_GAP_FILE, "a", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(header)
        writer.writerow([
            datetime.now().strftime("%Y-%m-%d"),
            gap_info["gap_type"],
            gap_info["gap_size"],
            gap_info["friday_close"],
            gap_info["sunday_open"],
            "pending",
            ""
        ])
    print(f"ğŸ“Š Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ø«Ø¨Øª Ø´Ø¯: {gap_info['gap_type']} {gap_info['gap_size']}%")

# Ø¨Ø±Ø±Ø³ÛŒ Ù¾Ø± Ø´Ø¯Ù† Ú¯Ù¾
def check_gap_fill(current_price):
    if not os.path.exists(BTC_GAP_FILE):
        print("â„¹ï¸ Ù‡ÛŒÚ† Ú¯Ø²Ø§Ø±Ø´ÛŒ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ Ú¯Ù¾ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø±Ø¯.")
        return

    updated_rows = []
    filled = False

    with open(BTC_GAP_FILE, "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        rows = list(reader)

    for row in rows:
        if row["status"] == "pending":
            friday_close = float(row["friday_close"])
            gap_type = row["gap_type"]
            if (gap_type == "up" and current_price <= friday_close) or \
               (gap_type == "down" and current_price >= friday_close):
                row["status"] = "filled"
                row["fill_time"] = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                filled = True
        updated_rows.append(row)

    with open(BTC_GAP_FILE, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=rows[0].keys())
        writer.writeheader()
        writer.writerows(updated_rows)

    if filled:
        print("âœ… Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ù¾Ø± Ø´Ø¯ Ùˆ Ú¯Ø²Ø§Ø±Ø´ Ø¢Ù¾Ø¯ÛŒØª Ø´Ø¯.")
    else:
        print("â„¹ï¸ Ù‡Ù†ÙˆØ² Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ù¾Ø± Ù†Ø´Ø¯Ù‡.")

        # ================== Ø¨Ø®Ø´ Û¸/Û·: ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ø§Ø±Ø³Ø§Ù„ Ùˆ Ú¯Ø²Ø§Ø±Ø´ ==================
import csv
import os

def load_reports():
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ù…Ø­ØªÙˆØ§ÛŒ reports*.csv (logs/) Ø¨Ù‡ ØµÙˆØ±Øª Ù„ÛŒØ³Øª Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ Ø¨Ø§ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² Ù¾Ø§Ø±Øªâ€ŒÙ‡Ø§"""
    try:
        base_dir = REPORTS_DIR
        files = sorted([
            os.path.join(base_dir, f) for f in os.listdir(base_dir)
            if f.startswith(REPORTS_BASE_NAME) and f.endswith(REPORTS_EXT)
        ])
        if not files:
            return []
        rows = []
        for p in files:
            with open(p, "r", encoding="utf-8") as f:
                rows.extend(list(csv.DictReader(f)))
        return rows
    except Exception:
        return []

def send_daily_report(chat_id=None, reply_markup=None):
    """Ø§Ø±Ø³Ø§Ù„ Ø¢Ø®Ø±ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø§Ø² reports.csv (ÙÙ‚Ø· Ø¨Ù‡ Ú†Øª Ø®ØµÙˆØµÛŒ)"""
    reports = load_reports()
    if not reports:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    daily = [r for r in reports if r.get("type") == "daily"]
    if not daily:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = daily[-1]
    text = f"ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡\nØªØ§Ø±ÛŒØ®: {last.get('timestamp','-')}\nØ®Ù„Ø§ØµÙ‡: {last.get('message','-')}"
    send_report(text)

def send_weekly_report(chat_id=None, reply_markup=None):
    """Ø§Ø±Ø³Ø§Ù„ Ø¢Ø®Ø±ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø§Ø² reports.csv (ÙÙ‚Ø· Ø¨Ù‡ Ú†Øª Ø®ØµÙˆØµÛŒ)"""
    reports = load_reports()
    if not reports:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    weekly = [r for r in reports if r.get("type") == "weekly"]
    if not weekly:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = weekly[-1]
    text = f"ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ\nØªØ§Ø±ÛŒØ®: {last.get('timestamp','-')}\nØ®Ù„Ø§ØµÙ‡: {last.get('message','-')}"
    send_report(text)

def send_monthly_report(chat_id=None, reply_markup=None):
    """Ø§Ø±Ø³Ø§Ù„ Ø¢Ø®Ø±ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø§Ø² reports.csv (ÙÙ‚Ø· Ø¨Ù‡ Ú†Øª Ø®ØµÙˆØµÛŒ)"""
    reports = load_reports()
    if not reports:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    monthly = [r for r in reports if r.get("type") == "monthly"]
    if not monthly:
        send_report("âš ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = monthly[-1]
    text = f"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡\nØªØ§Ø±ÛŒØ®: {last.get('timestamp','-')}\nØ®Ù„Ø§ØµÙ‡: {last.get('message','-')}"
    send_report(text)

# ================== Ø¨Ø®Ø´ Û¹: Ù…Ù†ÙˆÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ + Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ùˆ Ù„Ø§Ú¯ Ø´ÙØ§Ù ==================
from datetime import datetime

# Ø§Ø®ØªÛŒØ§Ø±ÛŒ: Ø®ØµÙˆØµÛŒâ€ŒØ³Ø§Ø²ÛŒ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ø§Øª (ÙÙ‚Ø· Ø®ÙˆØ¯Øª)
ALLOWED_USERS = set()
try:
    if CHAT_ID_USER and CHAT_ID_USER.strip():
        ALLOWED_USERS = {int(CHAT_ID_USER)}
except Exception:
    ALLOWED_USERS = set()

def send_main_menu(chat_id: int):
    keyboard = {
        "keyboard": [
            [{"text": "ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡"}, {"text": "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ"}],
            [{"text": "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡"}, {"text": "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†"}],
            [{"text": "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡"}, {"text": "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù‡ÙØªÚ¯ÛŒ"}],
            [{"text": "ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡"}]
        ],
        "resize_keyboard": True,
        "one_time_keyboard": False
    }
    payload = {
        "chat_id": chat_id,
        "text": "Ù…Ù†ÙˆÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ ÙØ¹Ø§Ù„ Ø§Ø³Øª. Ø§Ø² Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ø²ÛŒØ± Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†:",
        "reply_markup": keyboard
    }
    try:
        requests.post(f"{BOT_API}/sendMessage", json=payload, timeout=12)
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù…Ù†Ùˆ:", e)

def handle_message(msg: dict):
    chat_id = msg.get("chat", {}).get("id")
    text = (msg.get("text") or "").strip()
    if not chat_id:
        return

    # ÙÛŒÙ„ØªØ± Ø¯Ø³ØªØ±Ø³ÛŒ Ø®ØµÙˆØµÛŒ
    if ALLOWED_USERS and chat_id not in ALLOWED_USERS:
        return

    if text == "/start":
        send_main_menu(chat_id)
        send_report("âœ‹ Ø®ÙˆØ´ Ø¢Ù…Ø¯ÛŒ! Ù…Ù†ÙˆÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ ÙØ¹Ø§Ù„ Ø´Ø¯. Ø§Ø² Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†.")
        return

    if text.startswith("ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡"):
        send_daily_report()
        return

    if text.startswith("ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ"):
        send_weekly_report()
        return

    if text.startswith("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡"):
        send_monthly_report()
        return

    if text.startswith("ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†"):
        summary = summarize_gaps()
        send_report(summary)
        return

    if text.startswith("ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡"):
        msg_txt = send_daily_summary()
        if isinstance(msg_txt, str) and msg_txt.strip():
            send_report(msg_txt)
        else:
            send_report(build_daily_message())
        return

    if text.startswith("ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù‡ÙØªÚ¯ÛŒ"):
        send_report(build_weekly_message())
        return

    if text.startswith("ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡"):
        send_report(build_monthly_message())
        return

    if text in ["ğŸ Ù…Ù†ÙˆÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ", "Ù…Ù†ÙˆÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÚ¯ÛŒØ±ÛŒ", "Ù…Ù†Ùˆ"]:
        send_main_menu(chat_id)
        return

    send_report("Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø§Ø² Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù¾Ø§ÛŒÛŒÙ† Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù† âœ…")

    # ================== Ø¨Ø®Ø´ Û¹/Û±: Ø²Ù…Ø§Ù†â€ŒØ¨Ù†Ø¯ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ + Ù„Ø§Ú¯ Ø´ÙØ§Ù (Ø§ØµÙ„Ø§Ø­â€ŒØ´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Û· ØªØ§ Û¹ ØµØ¨Ø­) ==================
from datetime import datetime, timedelta

daily_done_today = False
weekly_done_this_week = False
monthly_done_this_month = False

def collect_data(start: datetime, end: datetime):
    """Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø§Ø² LOG_FILE_PATH Ùˆ Ø³Ø§Ø®Øª Ø®Ù„Ø§ØµÙ‡ Ø¨Ø§ build_summary_message"""
    df = load_log_df()
    if df is None or df.empty:
        return {"summary": f"Ø¨Ø§Ø²Ù‡: {start.date()} ØªØ§ {end.date()}\nØ¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª."}

    # Ø§Ø·Ù…ÛŒÙ†Ø§Ù† Ø§Ø² timezone
    start_ts = pd.Timestamp(start, tz=timezone.utc)
    end_ts = pd.Timestamp(end, tz=timezone.utc)

    # Ù…Ø­Ø§ÙØ¸Øª Ø§Ø² Ø³ØªÙˆÙ†â€ŒÙ‡Ø§
    needed_cols = ["timestamp", "result", "symbol", "analysis", "tf", "rrr"]
    for col in needed_cols:
        if col not in df.columns:
            df[col] = "" if col != "rrr" else pd.Series(dtype=float)

    mask = (df["timestamp"] >= start_ts) & (df["timestamp"] <= end_ts)
    dfx = df[mask]
    title = f"Ø¨Ø§Ø²Ù‡: {start.date()} ØªØ§ {end.date()}"
    msg = build_summary_message(title, dfx)
    return {"summary": msg}

def save_report(rep_type: str, data: dict, start: datetime, end: datetime):
    """Ø°Ø®ÛŒØ±Ù‡ Ø®Ù„Ø§ØµÙ‡ Ø¯Ø± reports.csv Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ (logs/...)"""
    title_map = {
        "daily": "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡",
        "weekly": "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ",
        "monthly": "ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡",
    }
    title = title_map.get(rep_type, "ğŸ“„ Ú¯Ø²Ø§Ø±Ø´")
    summary = data.get("summary", "Ù‡ÛŒÚ†")
    append_report(rep_type, f"{title}\n{summary}")

def build_daily_report(now: datetime):
    yesterday = now.date() - timedelta(days=1)
    start = datetime.combine(yesterday, datetime.min.time())
    end   = datetime.combine(yesterday, datetime.max.time())

    data = collect_data(start, end)
    save_report("daily", data, start, end)
    # Ø§Ø±Ø³Ø§Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø¨Ù‡ Ú†Øª Ø®ØµÙˆØµÛŒ
    send_report(f"ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯:\n{data['summary']}")
    return data

def build_weekly_report(now: datetime):
    start_of_this_week = now.date() - timedelta(days=now.weekday())
    start_of_last_week = start_of_this_week - timedelta(days=7)
    end_of_last_week   = start_of_this_week - timedelta(seconds=1)

    start = datetime.combine(start_of_last_week, datetime.min.time())
    end   = datetime.combine(end_of_last_week, datetime.max.time())

    data = collect_data(start, end)
    save_report("weekly", data, start, end)
    send_report(f"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯:\n{data['summary']}")
    return data

def build_monthly_report(now: datetime):
    first_of_this_month = now.replace(day=1)
    last_day_prev_month = first_of_this_month - timedelta(days=1)
    first_day_prev_month = last_day_prev_month.replace(day=1)

    start = datetime.combine(first_day_prev_month, datetime.min.time())
    end   = datetime.combine(last_day_prev_month, datetime.max.time())

    data = collect_data(start, end)
    save_report("monthly", data, start, end)
    send_report(f"ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø¢Ù…Ø§Ø¯Ù‡ Ø´Ø¯:\n{data['summary']}")
    return data

def schedule_reports(now: datetime):
    global daily_done_today, weekly_done_this_week, monthly_done_this_month

    # --- Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ ---
    if 7 <= now.hour < 9 and not daily_done_today:
        try:
            build_daily_report(now)
            daily_done_today = True
            print("âœ… [DAILY] Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        except Exception as e:
            print("âŒ [DAILY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡:", e)

    if now.hour < 7:
        daily_done_today = False

    # --- Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ ---
    if now.weekday() == 5 and 7 <= now.hour < 9 and not weekly_done_this_week:
        try:
            build_weekly_report(now)
            weekly_done_this_week = True
            print("âœ… [WEEKLY] Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        except Exception as e:
            print("âŒ [WEEKLY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ:", e)

    if now.weekday() == 5 and now.hour < 7:
        weekly_done_this_week = False

    # --- Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ---
    if now.day == 1 and 7 <= now.hour < 9 and not monthly_done_this_month:
        try:
            build_monthly_report(now)
            monthly_done_this_month = True
            print("âœ… [MONTHLY] Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ Ø³Ø§Ø®ØªÙ‡ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        except Exception as e:
            print("âŒ [MONTHLY] Ø®Ø·Ø§ Ø¯Ø± Ø³Ø§Ø®Øª Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡:", e)

    if now.day == 1 and now.hour < 7:
        monthly_done_this_month = False

    # --- Ù„Ø§Ú¯ Ø´ÙØ§Ù ---
    log_report_check(now, daily_done_today, weekly_done_this_week, monthly_done_this_month)

def log_report_check(now, daily_done_today, weekly_done_this_week, monthly_done_this_month):
    stamp = now.strftime("%Y-%m-%d %H:%M:%S")
    print(f"â³ [{stamp}] Ø¨Ø±Ø±Ø³ÛŒ Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ | "
          f"Ø±ÙˆØ²Ø§Ù†Ù‡={'OK' if daily_done_today else 'WAIT'} | "
          f"Ù‡ÙØªÚ¯ÛŒ={'OK' if weekly_done_this_week else 'WAIT'} | "
          f"Ù…Ø§Ù‡Ø§Ù†Ù‡={'OK' if monthly_done_this_month else 'WAIT'}")

          # ================== Ø¨Ø®Ø´ Û±Û° (Ù‚Ø³Ù…Øª A): Ø§Ø¨Ø²Ø§Ø± Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ + Ø®Ù„Ø§ØµÙ‡ Ú¯Ù¾â€ŒÙ‡Ø§ + Ù‡Ù†Ø¯Ù„ Ù…Ù†Ùˆ ==================
import time
import csv
import requests
import os
from datetime import datetime
from telegram import ReplyKeyboardMarkup

# ------------ Ø§Ø¨Ø²Ø§Ø±Ù‡Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ú¯Ø²Ø§Ø±Ø´ Ø§Ø² reports.csv ------------
def _read_reports_by_type(rep_type):
    """Ø®ÙˆØ§Ù†Ø¯Ù† Ø¢Ø®Ø±ÛŒÙ† Ú¯Ø²Ø§Ø±Ø´â€ŒÙ‡Ø§ Ø§Ø² logs/reports*.csv Ø¨Ø± Ø§Ø³Ø§Ø³ type ('daily' | 'weekly' | 'monthly')"""
    try:
        base_dir = REPORTS_DIR
        files = sorted([
            os.path.join(base_dir, f) for f in os.listdir(base_dir)
            if f.startswith(REPORTS_BASE_NAME) and f.endswith(REPORTS_EXT)
        ])
        rows = []
        for p in files:
            with open(p, "r", encoding="utf-8") as f:
                rows.extend([r for r in csv.DictReader(f)
                             if (r.get("type") or "").strip().lower() == rep_type])
        return rows
    except Exception:
        return []

def send_daily_report():
    rows = _read_reports_by_type("daily")
    if not rows:
        send_report("âŒ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = rows[-1]
    date = last.get("timestamp", "").strip()
    summary = last.get("message", "").strip()
    msg = f"ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡ ({date})\n{summary}"
    send_report(msg)

def send_weekly_report():
    rows = _read_reports_by_type("weekly")
    if not rows:
        send_report("âŒ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = rows[-1]
    date = last.get("timestamp", "").strip()
    summary = last.get("message", "").strip()
    msg = f"ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ ({date})\n{summary}"
    send_report(msg)

def send_monthly_report():
    rows = _read_reports_by_type("monthly")
    if not rows:
        send_report("âŒ Ú¯Ø²Ø§Ø±Ø´ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ù†ÛŒØ³Øª.")
        return
    last = rows[-1]
    date = last.get("timestamp", "").strip()
    summary = last.get("message", "").strip()
    msg = f"ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡ ({date})\n{summary}"
    send_report(msg)

# ------------ Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† ------------
def summarize_gaps():
    """Ø®Ù„Ø§ØµÙ‡ ÙˆØ¶Ø¹ÛŒØª Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ† Ø§Ø² btc_gaps.csv"""
    try:
        with open("btc_gaps.csv", "r", encoding="utf-8") as f:
            reader = csv.DictReader(f)
            rows = list(reader)

        total = len(rows)
        filled = sum(1 for r in rows if (r.get("status") or "").strip().lower() == "filled")
        pending = sum(1 for r in rows if (r.get("status") or "").strip().lower() == "pending")

        last_pending = None
        for r in reversed(rows):
            if (r.get("status") or "").strip().lower() == "pending":
                last_pending = r
                break

        msg = "ğŸ“ˆ ÙˆØ¶Ø¹ÛŒØª Ú¯Ù¾â€ŒÙ‡Ø§ÛŒ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†:\n"
        msg += f"- Ú©Ù„ Ú¯Ù¾â€ŒÙ‡Ø§: {total}\n"
        msg += f"- Ù¾Ø± Ø´Ø¯Ù‡: {filled}\n"
        msg += f"- Ø¨Ø§Ø²: {pending}\n"
        if last_pending:
            msg += f"- Ø¢Ø®Ø±ÛŒÙ† Ú¯Ù¾ Ø¨Ø§Ø²: {last_pending.get('date','')} ({last_pending.get('gap_type','')} Gap, {last_pending.get('gap_size','')}%)\n"
        return msg
    except Exception as e:
        return f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† Ú¯Ù¾â€ŒÙ‡Ø§: {e}"

# ------------ Ù‡Ù†Ø¯Ù„ Ù…Ù†ÙˆÛŒ ØªÙ„Ú¯Ø±Ø§Ù… ------------
def handle_message(msg, reply_markup=None):
    text = (msg.get("text") or "").strip()

    if text == "ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡":
        send_daily_report(); return
    if text == "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ":
        send_weekly_report(); return
    if text == "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡":
        send_monthly_report(); return
    if text == "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†":
        summary = summarize_gaps()
        send_report(summary); return

    if text == "ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡":
        msg_txt = send_daily_summary()
        send_report(msg_txt); return
    if text == "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù‡ÙØªÚ¯ÛŒ":
        send_report(build_weekly_message()); return
    if text == "ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡":
        send_report(build_monthly_message()); return

    send_report("â“ Ú¯Ø²ÛŒÙ†Ù‡ Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª.")


# ================== Ø¨Ø®Ø´ Û±Û° (Ù‚Ø³Ù…Øª B): Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ + Ù…Ù†Ùˆ + ÙˆØ±ÙˆØ¯ Ø¨Ø±Ù†Ø§Ù…Ù‡ ==================
import time
import requests
from datetime import datetime
from telegram import ReplyKeyboardMarkup

def run_bot_loop():
    try:
        requests.get(f"{BOT_API}/deleteWebhook", timeout=10)
        print("ğŸ§¹ Webhook Ø­Ø°Ù Ø´Ø¯")
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± deleteWebhook:", e)

    try:
        requests.get(f"{BOT_API}/getUpdates", params={"offset": -1}, timeout=10)
        print("âœ… ØµÙ Ù‚Ø¯ÛŒÙ…ÛŒ Ù¾Ø§Ú© Ø´Ø¯")
    except Exception as e:
        print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø§Ú© Ú©Ø±Ø¯Ù† Ø¢Ù¾Ø¯ÛŒØªâ€ŒÙ‡Ø§:", e)

    offset = None
    last_run = 0
    run_interval = 3600
    last_proxy_error = 0

    print("â–¶ï¸ Ø´Ø±ÙˆØ¹ Ø§Ø¬Ø±Ø§ÛŒ Ø­Ù„Ù‚Ù‡ Ø±Ø¨Ø§Øª...")

    menu_keyboard = [
        ["ğŸ“… Ú¯Ø²Ø§Ø±Ø´ Ø±ÙˆØ²Ø§Ù†Ù‡", "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ù‡ÙØªÚ¯ÛŒ"],
        ["ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ù…Ø§Ù‡Ø§Ù†Ù‡", "ğŸ“ˆ Ú¯Ø²Ø§Ø±Ø´ Ú¯Ù¾ Ø¨ÛŒØªâ€ŒÚ©ÙˆÛŒÙ†"],
        ["ğŸ“Š Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ø±ÙˆØ²Ø§Ù†Ù‡", "ğŸ“† Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù‡ÙØªÚ¯ÛŒ"],
        ["ğŸ—“ï¸ Ú¯Ø²Ø§Ø±Ø´ Ø³Ø§Ø¯Ù‡ Ù…Ø§Ù‡Ø§Ù†Ù‡"]
    ]
    reply_markup = ReplyKeyboardMarkup(menu_keyboard, resize_keyboard=True)

    while True:
        try:
            now_ts = time.time()
            if now_ts - last_run >= run_interval:
                try:
                    run_once()
                    check_motivation_message()
                except Exception as e_run:
                    print("âŒ Ø®Ø·Ø§ Ø¯Ø± run_once:", e_run)
                last_run = now_ts

            try:
                schedule_reports(datetime.now())
            except Exception as e_rep:
                print("âŒ Ø®Ø·Ø§ Ø¯Ø± schedule_reports:", e_rep)

            url = f"{BOT_API}/getUpdates"
            params = {"timeout": 30}
            if offset is not None:
                params["offset"] = offset
            r = requests.get(url, params=params, timeout=35)
            data = r.json()

            for update in data.get("result", []):
                offset = update["update_id"] + 1
                msg = update.get("message")
                if msg and isinstance(msg.get("text"), str):
                    handle_message(msg, reply_markup=reply_markup)

        except Exception as e:
            if "proxy" in str(e).lower():
                if time.time() - last_proxy_error > 60:
                    print("âš ï¸ Ø®Ø·Ø§ÛŒ Ù¾Ø±ÙˆÚ©Ø³ÛŒ: Ø§ØªØµØ§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù… Ù…Ù…Ú©Ù† Ù†ÛŒØ³Øª.")
                    last_proxy_error = time.time()
            else:
                print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø­Ù„Ù‚Ù‡ Ø§ØµÙ„ÛŒ:", e)

        time.sleep(300)

if __name__ == "__main__":
    init_log(get_current_log_path())
    load_last_signals()
    run_bot_loop()